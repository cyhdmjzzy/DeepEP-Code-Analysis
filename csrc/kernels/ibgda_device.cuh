// Portions derived from NVSHMEM (https://developer.nvidia.com/nvshmem)
// Copyright (c) NVIDIA Corporation.
// Licensed under the NVSHMEM Software License Agreement (version: September 3, 2019).
// See full license at: https://docs.nvidia.com/nvshmem/api/sla.html
//
// Modified from original source:
//  - nvshmem/src/include/non_abi/device/pt-to-pt/ibgda_device.cuh
#pragma once

#include "configs.cuh"
#include "exception.cuh"
#include "utils.cuh"

namespace deep_ep {

EP_STATIC_ASSERT(NVSHMEMI_IBGDA_MIN_QP_DEPTH >= 64, "Invalid QP minimum depth");

__device__ static __forceinline__ uint64_t HtoBE64(uint64_t x) {
    uint64_t ret;
    asm("{\n\t"
        ".reg .b32 ign;\n\t"
        ".reg .b32 lo;\n\t"
        ".reg .b32 hi;\n\t"
        ".reg .b32 new_lo;\n\t"
        ".reg .b32 new_hi;\n\t"
        "mov.b64 {lo,hi}, %1;\n\t"
        "prmt.b32 new_hi, lo, ign, 0x0123;\n\t"
        "prmt.b32 new_lo, hi, ign, 0x0123;\n\t"
        "mov.b64 %0, {new_lo,new_hi};\n\t"
        "}"
        : "=l"(ret)
        : "l"(x));
    return ret;
}

__device__ static __forceinline__ uint32_t HtoBE32(uint32_t x) {
    uint32_t ret;
    asm("{\n\t"
        ".reg .b32 ign;\n\t"
        "prmt.b32 %0, %1, ign, 0x0123;\n\t"
        "}"
        : "=r"(ret)
        : "r"(x));
    return ret;
}

__device__ static __forceinline__ uint16_t HtoBE16(uint16_t x) {
    // TODO: simplify PTX using 16-bit instructions
    auto a = static_cast<uint32_t>(x);
    uint32_t d;
    asm volatile(
        "{\n\t"
        ".reg .b32 mask;\n\t"
        ".reg .b32 ign;\n\t"
        "mov.b32 mask, 0x4401;\n\t"
        "mov.b32 ign, 0x0;\n\t"
        "prmt.b32 %0, %1, ign, mask;\n\t"
        "}"
        : "=r"(d)
        : "r"(a));
    return static_cast<uint16_t>(d);
}

typedef struct mlx5_wqe_ctrl_seg __attribute__((__aligned__(8))) ibgda_ctrl_seg_t;

typedef struct {
    uint32_t add_data;
    uint32_t field_boundary;
    uint64_t reserved;
} __attribute__((__packed__)) ibgda_atomic_32_masked_fa_seg_t;

__device__ static __forceinline__ nvshmemi_ibgda_device_state_t* ibgda_get_state() {
    /*
    è¿™æ˜¯nvshmemæºç ä¸­çš„ä¸€è¡Œ: __constant__ nvshmemi_device_host_state_t nvshmemi_device_state_d;
    å°±æ˜¯è¯´ nvshmemi_device_state_d æ˜¯ nvshmemi_device_host_state_tç±»å‹çš„ä¸€ä¸ªå¯¹è±¡ï¼Œæ˜¯å˜é‡åã€‚
    __constant__: æ˜¯ CUDA å­˜å‚¨ç±»é™å®šç¬¦, è¡¨ç¤ºå˜é‡ä½äºå¸¸é‡å†…å­˜ç©ºé—´ã€‚åªè¯»ï¼Œå¯é€šè¿‡ __ldg() é«˜æ•ˆè¯»å–ã€‚
    æ‰€æœ‰çº¿ç¨‹å…±äº«ï¼Œç”Ÿå‘½å‘¨æœŸä¸ç¨‹åºç›¸åŒã€‚
    */
    return &nvshmemi_ibgda_device_state_d;
}

__device__ static __forceinline__ nvshmemi_ibgda_device_qp_t* ibgda_get_rc(int pe, int id) {
    auto state = ibgda_get_state();
    /*
    pe: å½“å‰PEçš„ç›®æ ‡PEçš„ç¼–å·ã€‚

    num_rc_per_pe: æ¯ä¸ª PEï¼ˆProcessing Elementï¼‰åœ¨æ¯ä¸ª NIC ä¸Šåˆ†é…çš„ RCï¼ˆReliable Connectionï¼‰é˜Ÿåˆ—å¯¹ï¼ˆQueue Pair, QPï¼‰æ•°é‡ã€‚
                   RC æ˜¯ InfiniBand ä¸­çš„ä¸€ç§ QP ç±»å‹ï¼Œæä¾›å¯é ã€æœ‰åºçš„ç‚¹å¯¹ç‚¹é€šä¿¡ã€‚
    
    æ¦‚å¿µ	                    å«ä¹‰	                                èŒƒå›´	       è®¡ç®—å…¬å¼
    num_devices_initialized	   å½“å‰ PE é€‰æ‹©å¹¶æˆåŠŸåˆå§‹åŒ–çš„ NIC è®¾å¤‡æ•°é‡	    PE çº§åˆ«	      n_devs_selected
    num_rc_per_pe              æ¯ä¸ª PE åœ¨æ¯ä¸ª NIC è®¾å¤‡ä¸Šçš„ RC QP æ•°é‡	  PE Ã— è®¾å¤‡	    num_rc_handles / n_devs_selected / n_pes
    æ¯ä¸ª PE çš„æ€» RC æ•°           æ¯ä¸ª PE åœ¨æ‰€æœ‰NICè®¾å¤‡ä¸Šçš„ RC æ€»æ•°	        PE çº§åˆ«	      num_devices_initialized Ã— num_rc_per_pe
    */
    const auto num_rc_per_pe = ibgda_get_state()->num_rc_per_pe;
    /*
    globalmem: å…¨å±€å†…å­˜åŒºåŸŸã€‚
    rcs: RC QP æ•°ç»„ï¼Œæ•°ç»„å…ƒç´ ç±»å‹ä¸º nvshmemi_ibgda_device_qp_t *
    globalmem.rcs çš„æ•°ç»„å¤§å°: n_pes Ã— num_rc_per_pe Ã— num_devices_initialized
    n_pes çš„å«ä¹‰: æ•´ä¸ªé›†ç¾¤ï¼ˆå¤šæœºå¤šå¡ï¼‰ä¸­çš„æ‰€æœ‰ PE æ€»æ•°

    æ¯ä¸ª PE å ç”¨ num_rc_per_pe * num_devices_initialized ä¸ªè¿ç»­çš„ RC QPã€‚
    id: å³ dst_expert_local_idx æˆ– local_expert_idxã€‚å®é™…ä¸Šå¯ä»¥æ˜¯ä»»ä½•éœ€è¦è¿›è¡Œè´Ÿè½½å‡è¡¡é€šä¿¡çš„é€»è¾‘å®ä½“ã€‚
    id % (num_rc_per_pe * state->num_devices_initialized): rc_idx

    äº‹å®ä¸Šï¼Œæœ‰æ–­è¨€:
    1ã€internode_ll.cu ä¸­: EP_DEVICE_ASSERT(ibgda_get_state()->num_rc_per_pe >= num_local_experts);
    2ã€internode.cu ä¸­:    EP_DEVICE_ASSERT(ibgda_get_state()->num_rc_per_pe == num_channels or ibgda_get_state()->num_rc_per_pe >= num_sms);

    è¿”å›ä¸€ä¸ªè´Ÿè½½å‡è¡¡åçš„ RC QP çš„æŒ‡é’ˆï¼Œç±»å‹ä¸º nvshmemi_ibgda_device_qp_t *
    */
    return &state->globalmem.rcs[pe * num_rc_per_pe * state->num_devices_initialized + id % (num_rc_per_pe * state->num_devices_initialized)];
}

__device__ static __forceinline__ void ibgda_lock_acquire(int* lock) {
    while (atomicCAS(lock, 0, 1) == 1)
        ;

    // Prevent reordering before the lock is acquired
    /*
    memory_fence_cta(): ctaçº§åˆ«çš„å†…å­˜å±éšœ
    ä½œç”¨: é˜²æ­¢åœ¨è·å–é”ä¹‹å‰çš„å†…å­˜æ“ä½œè¢«é‡æ’åºåˆ°è·å–é”ä¹‹ã€‚å³â€œacquireåä¸åˆ°å‰â€
    ä¿è¯: è·å–é”ä¹‹åï¼Œä¹‹å‰çš„æ‰€æœ‰å†…å­˜æ“ä½œå¯¹å…¶ä»–çº¿ç¨‹å¯è§
    */
    memory_fence_cta();
}

__device__ static __forceinline__ void ibgda_lock_release(int* lock) {
    memory_fence_cta();

    // Prevent reordering before lock is released
    st_na_relaxed(lock, 0);
}

__device__ static __forceinline__ void ibgda_update_dbr(nvshmemi_ibgda_device_qp_t* qp, uint32_t dbrec_head) {
    /*
    dbrec_head: å°±æ˜¯ new_prod_idxï¼Œé—¨é“ƒè®°å½•çš„ç´¢å¼•ã€‚
    */
    
    // `DBREC` contains the index of the next empty `WQEBB`
    __be32 dbrec_val;  // å¤§ç«¯åº32ä½æ•´æ•°ï¼Œå­˜å‚¨è¦å†™å…¥DBRECçš„å€¼ï¼ˆå¤§ç«¯åºè½¬æ¢åçš„ï¼‰
    /*
    tx çš„å…¨ç§°æ˜¯ Transmitï¼ˆå‘é€/ä¼ è¾“ï¼‰
    qp->tx_wq.dbrec: é—¨é“ƒè®°å½•æŒ‡é’ˆï¼ŒæŒ‡å‘é—¨é“ƒè®°å½•çš„å†…å­˜åœ°å€ã€‚åœ¨GPUå†…å­˜ï¼Œæ˜ å°„åˆ°NICçš„DoorbellåŒºåŸŸã€‚
    */
    __be32* dbrec_ptr = qp->tx_wq.dbrec;

    // This is equivalent to `WRITE_ONCE(dbrec_ptr, HtoBE32(dbrec_head & 0xffff))`
    /*
    ä¸‹é¢çš„asmç›¸å½“äº: dbrec_val = HtoBE32(dbrec_head & 0xffff)
    */
    asm("{\n\t"
        ".reg .b32 dbrec_head_16b;\n\t"                     // å£°æ˜32ä½å¯„å­˜å™¨å˜é‡
        ".reg .b32 ign;\n\t"                                // å£°æ˜å¿½ç•¥å¯„å­˜å™¨
        "and.b32 dbrec_head_16b, %1, 0xffff;\n\t"           // å°†dbrec_headçš„ä½16ä½èµ‹å€¼ç»™dbrec_head_16b
        "prmt.b32 %0, dbrec_head_16b, ign, 0x123;\n\t"      // å°†dbrec_head_16bçš„å€¼è½¬æ¢ä¸ºå¤§ç«¯åº
        "}"
        : "=r"(dbrec_val)                                   // è¾“å‡ºå‚æ•°ï¼Œå¤§ç«¯åº32ä½æ•´æ•°å€¼
        : "r"(dbrec_head));
    // å°† dbrec_val å†™å…¥ dbrec_ptr æŒ‡å‘çš„å†…å­˜ä½ç½®
    st_na_release(dbrec_ptr, dbrec_val);
}

__device__ static __forceinline__ void ibgda_ring_db(nvshmemi_ibgda_device_qp_t* qp, uint16_t prod_idx) {
    // é—¨é“ƒå¯„å­˜å™¨ï¼ˆBlueFlameï¼‰
    auto bf_ptr = reinterpret_cast<uint64_t*>(qp->tx_wq.bf);
    ibgda_ctrl_seg_t ctrl_seg = {.opmod_idx_opcode = HtoBE32(prod_idx << 8), .qpn_ds = HtoBE32(qp->qpn << 8)};

    EP_STATIC_ASSERT(sizeof(decltype(&ctrl_seg)) == sizeof(uint64_t), "");
    st_na_release(bf_ptr, *(reinterpret_cast<uint64_t*>(&ctrl_seg)));
}

__device__ static __forceinline__ void ibgda_post_send(nvshmemi_ibgda_device_qp_t* qp, uint64_t new_prod_idx) {
    nvshmemi_ibgda_device_qp_management_t* mvars = &qp->mvars;
    uint64_t old_prod_idx;

    // Update `prod_idx` before ringing the doorbell, so that we know which index is needed in quiet/fence
    // 
    /*
    &mvars->post_send_lock: é—¨é“ƒæäº¤é”ã€‚
    åœ¨æ•²å“é—¨é“ƒä¹‹å‰ä½¿ç”¨atomicMaxå‡½æ•°æ›´æ–° prod_idxï¼Œè¿™æ ·åœ¨ quiet/fence æ“ä½œæ—¶å°±çŸ¥é“éœ€è¦å“ªä¸ªç´¢å¼•ã€‚
    ä¸ä¸‹é¢çš„ibgda_lock_releaseå½¢æˆâ€œacquire-releaseâ€é…å¯¹ã€‚è¿™ä¹Ÿå¯ä»¥:
    é˜²æ­¢é‡æ’åº: ç¡®ä¿é”é‡Šæ”¾ä¹‹å‰çš„æ‰€æœ‰æ“ä½œéƒ½å·²å®Œæˆã€‚ å¯è§æ€§ä¿è¯: ç¡®ä¿å…¶ä»–çº¿ç¨‹èƒ½çœ‹åˆ°é”é‡Šæ”¾åçš„çŠ¶æ€æ›´æ–°ã€‚
    â€œacquireåä¸åˆ°å‰ï¼Œreleaseå‰ä¸åˆ°åâ€ã€‚
    */
    ibgda_lock_acquire(&mvars->post_send_lock);

    /*
    &mvars->tx_wq.ready_head: tx_qpä¸­å·²å‡†å¤‡å¥½æäº¤çš„WQEç´¢å¼•ã€‚
    &mvars->tx_wq.prod_idx: tx_qpä¸­å·²æäº¤ç»™NICçš„WQEçš„ç´¢å¼•ï¼ˆç”Ÿäº§è€…ç´¢å¼•ï¼‰ï¼Œç”±atomicMaxå‡½æ•°æ›´æ–°ã€‚

    åŒæ­¥æ¨¡å¼ä¸‹ï¼Œwqeå®Œæ•´çš„æµè½¬è¿‡ç¨‹ï¼šé¢„ç•™é˜¶æ®µï¼Œå†™å…¥é˜¶æ®µï¼Œå‡†å¤‡é˜¶æ®µï¼Œæäº¤é˜¶æ®µï¼ˆæ‰¹å¤„ç†è§¦å‘æ—¶ï¼‰ã€‚è€Œå¼‚æ­¥æ¨¡å¼ä¸éœ€è¦æäº¤é˜¶æ®µã€‚
    qp->tx_wq.wqe é˜Ÿåˆ—çŠ¶æ€ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ WQE 0 â”‚ WQE 1 â”‚ ... â”‚ WQE 8 â”‚ WQE 9 â”‚ WQE 10 â”‚     11 â”‚     12 â”‚     13 â”‚    ...â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†‘                        â†‘                  â†‘
                          prod_idx                 ready_head         resv_head
    ç´¢å¼•å…³ç³»ï¼š
    - resv_head = 13   (ä¸‹ä¸€ä¸ªå¯é¢„ç•™çš„WQEç´¢å¼•ï¼Œtx_wq.wqe[11, 13)è™½ç„¶é¢„ç•™äº†ä½†æ˜¯è¿˜æ²¡æœ‰å†™å…¥WQE )
    - ready_head = 11  (å·²å‡†å¤‡å¥½æäº¤çš„WQEç´¢å¼•ï¼ŒWQE[8, 11) å·²å‡†å¤‡å¥½)
    - prod_idx = 8     (å·²æäº¤ç»™NICçš„WQEç´¢å¼•ï¼ŒWQE[0, 8) å·²æäº¤)
    æ³¨æ„: åŒºåˆ† resv_head å’Œnew_wqe_idxã€‚
        resv_head: å…¨å±€çŠ¶æ€ï¼Œè¡¨ç¤ºâ€œä¸‹ä¸€ä¸ªå¯é¢„ç•™çš„WQEç´¢å¼•â€
        new_wqe_idx: å±€éƒ¨å˜é‡ï¼Œè¡¨ç¤ºâ€œæœ¬æ¬¡æ“ä½œï¼ˆwarpçº§çš„ï¼‰ä½¿ç”¨çš„æœ€åä¸€ä¸ªWQEçš„ä¸‹ä¸€ä¸ªç´¢å¼•â€
        åœ¨å¹¶å‘åœºæ™¯ä¸‹ï¼Œå®ƒä»¬å¯èƒ½ä¸ç›¸ç­‰ï¼ˆresv_head å¯èƒ½å·²è¢«å…¶ä»–warpæ›´æ–°ï¼‰ã€‚
    atomicMax(addr, val): è¯»å–addræŒ‡å‘çš„å€¼ï¼Œå¦‚æœ val > å½“å‰å€¼ï¼Œåˆ™å†™å…¥valå¹¶è¿”å›æ—§å€¼ï¼Œå¦‚æœ val <= å½“å‰å€¼ï¼Œåˆ™ä¸å†™å…¥ï¼Œè¿”å›å½“å‰å€¼ã€‚
    åŸå­æ€§: ä¿è¯å¤šçº¿ç¨‹å¹¶å‘æ—¶çš„æ­£ç¡®æ€§ã€‚
    å•è°ƒé€’å¢: prod_idx åªèƒ½å•è°ƒé€’å¢ï¼Œä¸èƒ½å›é€€ã€‚
    é¿å…è¦†ç›–: å¦‚æœå¤šä¸ªçº¿ç¨‹åŒæ—¶æ›´æ–°ï¼ŒatomicMax ç¡®ä¿å–æœ€å¤§å€¼ã€‚
    */
    old_prod_idx = atomicMax(reinterpret_cast<unsigned long long int*>(&mvars->tx_wq.prod_idx), new_prod_idx);
    /*
    new_prod_idx æ˜¯å½“å‰warpçš„æœ€åä¸€ä¸ªWQEçš„ä¸‹ä¸€ä¸ªç´¢å¼•ã€‚è€Œ&mvars->tx_wq.prod_idxæ˜¯æ‰€æœ‰warpå…±åŒç»´æŠ¤çš„ç”Ÿäº§è€…ç´¢å¼•ã€‚
    å½“å½“å‰warpçš„ç”Ÿäº§è€…ç´¢å¼•å¤§äºtx_qpä¸­å·²æäº¤ç»™NICçš„WQEçš„ç´¢å¼•æ—¶ï¼Œå°±éœ€è¦è§¦å‘é—¨é“ƒã€‚
    å¦‚æœ new_prod_idx <= old_prod_idxï¼Œè¯´æ˜å·²ç»æœ‰å…¶ä»–çº¿ç¨‹æ›´æ–°äº†æ›´å¤§çš„ç´¢å¼•ï¼Œä¸éœ€è¦é‡å¤è§¦å‘é—¨é“ƒã€‚
    åŠ æ¡ä»¶åˆ¤æ–­æ˜¯ä¸ºäº†é¿å…é‡å¤è§¦å‘ã€å‡å°‘ä¸å¿…è¦çš„é—¨é“ƒæ“ä½œï¼Œè¿™æ ·å¯ä»¥æé«˜æ€§èƒ½ã€‚
    */
    if (new_prod_idx > old_prod_idx) {
        // dbr: é—¨é“ƒè®°å½•ï¼ˆDBRï¼Œdoorbell recordï¼‰ç¼“å†²åŒºï¼ŒåŒæ ·ä½äº GPU å†…å­˜ä¸­ã€‚
        ibgda_update_dbr(qp, new_prod_idx);
        ibgda_ring_db(qp, new_prod_idx);
    }
    ibgda_lock_release(&mvars->post_send_lock);
}

template <bool kAlwaysDoPostSend>
__device__ static __forceinline__ void ibgda_submit_requests(nvshmemi_ibgda_device_qp_t* qp,
                                                             uint64_t base_wqe_idx,
                                                             uint32_t num_wqes,
                                                             int message_idx = 0) {
    auto state = ibgda_get_state();
    nvshmemi_ibgda_device_qp_management_t* mvars = &qp->mvars;
    // new_wqe_idx: è®¡ç®—å¾—åˆ°çš„æ–°WQEç´¢å¼•
    uint64_t new_wqe_idx = base_wqe_idx + num_wqes;

    // WQE writes must be finished first
    /* 
    ç¡®ä¿å½“å‰çº¿ç¨‹çš„æ‰€æœ‰å†…å­˜å†™å…¥æ“ä½œå¯¹å…¶ä»–çº¿ç¨‹å’Œè®¾å¤‡ï¼ˆå¦‚NICï¼‰å¯è§ã€‚
    GPUå¯èƒ½æœ‰**å†™ç¼“å†²åŒºï¼ˆWrite Bufferï¼‰**æ¥æš‚å­˜å†™å…¥æ“ä½œ
    __threadfence() å¼ºåˆ¶åˆ·æ–°å½“å‰çº¿ç¨‹çš„å†™ç¼“å†²åŒºï¼Œå®ƒä¼šé˜»å¡å½“å‰çº¿ç¨‹ï¼Œç›´åˆ°æ‰€æœ‰å¾…å†™å…¥çš„æ•°æ®éƒ½çœŸæ­£å†™å…¥åˆ°å…¨å±€å†…å­˜ï¼Œä¸”å¯¹å…¶ä»–çº¿ç¨‹å’Œè®¾å¤‡å¯è§ã€‚
    __threadfence() å»ºç«‹äº†happens-beforeå…³ç³»ï¼Œå±éšœä¹‹å‰çš„æ‰€æœ‰å†…å­˜å†™å…¥ï¼Œåœ¨å±éšœä¹‹åå¯¹å…¶ä»–çº¿ç¨‹å’Œè®¾å¤‡å¯è§ã€‚
    åœ¨æ­¤ä¹‹åï¼Œå…¶ä»–çº¿ç¨‹/NICæ‰èƒ½çœ‹åˆ°å®Œæ•´çš„WQEæ•°æ®ã€‚
    */
    __threadfence();

    /*
    state->use_async_postsend: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æäº¤æ¨¡å¼ã€‚
    QPç»“æ„ä½“ä¸­çš„ tx_wq:
    typedef struct nvshmemi_ibgda_device_qp {
        struct {
            uint16_t nwqes;                    // WQEé˜Ÿåˆ—å¤§å°
            void *wqe;                         // WQEé˜Ÿåˆ—å†…å­˜åŸºåœ°å€
            __be32 *dbrec;                     // Doorbell RecordæŒ‡é’ˆ
            void *bf;                          // å…¥é—¨é“ƒå¯„å­˜å™¨ï¼ˆBlueFlameï¼‰æŒ‡é’ˆ
            nvshmemi_ibgda_device_cq_t *cq;    // Completion QueueæŒ‡é’ˆ
            uint64_t *prod_idx;                // â† è¿™æ˜¯ä¸€ä¸ªæŒ‡é’ˆï¼
            // æ³¨é‡Š: "May point to mvars.prod_idx or internal prod_idx"
        } tx_wq;
        
        nvshmemi_ibgda_device_qp_management_v1 mvars;  // ç®¡ç†å˜é‡
    } nvshmemi_ibgda_device_qp_t;

    ç®¡ç†å˜é‡ä¸­çš„ tx_wq: 
    typedef struct {
        struct {
            uint64_t resv_head;    // å·²é¢„ç•™çš„WQEç´¢å¼•, ibgda_reserve_wqe_slots å‡½æ•°ä¸­è®¾ç½®ã€‚
            uint64_t prod_idx;     // â† è¿™æ˜¯ä¸€ä¸ªå€¼ï¼
            uint64_t ready_head;   // â† è¿™æ˜¯ä¸€ä¸ªå€¼ï¼
            uint64_t get_head;     // æœ€åä¸€ä¸ª"fetch"æ“ä½œçš„WQEç´¢å¼•
            uint64_t get_tail;     // æœ€åä¸€ä¸ªè¢«è½®è¯¢çš„WQEç´¢å¼•
        } tx_wq;
        // ... å…¶ä»–å­—æ®µ
    } nvshmemi_ibgda_device_qp_management_v1;
    */
    /*
    qp->tx_wq.prod_idx: NICå·²ç»å¤„ç†åˆ°å“ªä¸ªWQEäº†ã€‚è·Ÿè¸ªå·²æäº¤ç»™NICçš„WQEç´¢å¼•ã€‚åœ¨å¼‚æ­¥æ¨¡å¼ä¸‹ä½¿ç”¨: NICè‡ªåŠ¨è½®è¯¢ï¼Œæ›´æ–°è¿™ä¸ªç´¢å¼•ã€‚
    &mvars->tx_wq.ready_head: GPUå·²ç»å‡†å¤‡å¥½æäº¤åˆ°å“ªä¸ªWQEäº†ã€‚è·Ÿè¸ªå·²å‡†å¤‡å¥½æäº¤çš„WQEç´¢å¼•ã€‚
                              åœ¨åŒæ­¥æ¨¡å¼ä¸‹ä½¿ç”¨: GPUæ˜¾å¼æ§åˆ¶æäº¤ï¼Œä½¿ç”¨è¿™ä¸ªç´¢å¼•è·Ÿè¸ªå‡†å¤‡å¥½çš„WQEã€‚
    ready_idx ä¸æŒ‡å‘WQEæœ¬èº«ï¼Œè€Œæ˜¯æŒ‡å‘å­˜å‚¨WQEç´¢å¼•çš„å˜é‡ã€‚

    æƒ…å†µ1ï¼šå¼‚æ­¥æäº¤æ¨¡å¼ (use_async_postsend == true)ï¼Œé€‰æ‹©: qp->tx_wq.prod_idx
        å«ä¹‰: æŒ‡å‘å·²æäº¤ç»™NICçš„WQEç´¢å¼•ï¼ˆç”Ÿäº§è€…ç´¢å¼•ï¼‰
        ä½ç½®: æŒ‡å‘ qp->tx_wq.prod_idx
        ä½œç”¨: NICè‡ªåŠ¨è½®è¯¢ï¼Œä½¿ç”¨prod_idxè·Ÿè¸ªå·²å¤„ç†çš„WQEã€‚NICç¡¬ä»¶è‡ªåŠ¨è½®è¯¢WQEé˜Ÿåˆ—ï¼Œæ£€æŸ¥æ–°çš„WQEã€‚
        æ— éœ€é—¨é“ƒ: GPUä¸éœ€è¦æ˜¾å¼è§¦å‘é—¨é“ƒï¼ŒNICä¼šè‡ªåŠ¨å‘ç°æ–°çš„WQEã€‚
        ä½¿ç”¨ prod_idx: é€šè¿‡ qp->tx_wq.prod_idx è·Ÿè¸ªå·²æäº¤ç»™NICçš„WQEç´¢å¼•
        ä¼˜åŠ¿ï¼šæ›´é«˜ååé‡: NICå¯ä»¥æ‰¹é‡å¤„ç†å¤šä¸ªWQEï¼Œå‡å°‘ä¸­æ–­å¼€é”€ã€‚é€‚åˆé«˜ååé‡çš„åœºæ™¯ï¼ˆå¦‚è®­ç»ƒé˜¶æ®µï¼‰ã€‚
             å‡å°‘GPUå¼€é”€: GPUä¸éœ€è¦æ˜¾å¼è§¦å‘é—¨é“ƒï¼Œå‡å°‘GPUçº¿ç¨‹çš„å¼€é”€ï¼Œå‡å°‘é—¨é“ƒå¯„å­˜å™¨çš„å†™å…¥æ¬¡æ•°ã€‚
             æ›´å¥½çš„æ‰¹å¤„ç†: NICå¯ä»¥è‡ªåŠ¨æ‰¹é‡å¤„ç†WQEï¼Œæé«˜æ•ˆç‡ã€‚
        åŠ£åŠ¿ï¼šæ›´é«˜å»¶è¿Ÿ: NICè½®è¯¢æœ‰å»¶è¿Ÿï¼Œä¸èƒ½ç«‹å³å¤„ç†WQEã€‚ä¸é€‚åˆä½å»¶è¿Ÿçš„åœºæ™¯ï¼ˆå¦‚æ¨ç†é˜¶æ®µï¼‰ã€‚
             CPUè¾…åŠ©: å¯èƒ½éœ€è¦CPUè¾…åŠ©æ¥ç®¡ç†å¼‚æ­¥æäº¤ï¼Œå¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§ã€‚

    æƒ…å†µ2ï¼šåŒæ­¥æäº¤æ¨¡å¼ (use_async_postsend == false)ï¼Œé€‰æ‹©: &mvars->tx_wq.ready_head
        å«ä¹‰: æŒ‡å‘å·²å‡†å¤‡å¥½æäº¤çš„WQEç´¢å¼•
        ä½ç½®: ç®¡ç†å˜é‡ä¸­çš„ ready_head å­—æ®µ
        ä½œç”¨: GPUæ˜¾å¼æ§åˆ¶æäº¤ï¼Œä½¿ç”¨ready_headè·Ÿè¸ªå·²å‡†å¤‡å¥½æäº¤çš„WQEç´¢å¼•ã€‚ä½†æ˜¯è¿™äº›WQEè¿˜æ²¡æœ‰çœŸæ­£æäº¤ã€‚
        éœ€è¦é—¨é“ƒ: GPUæ˜¾å¼è°ƒç”¨ ibgda_post_send è§¦å‘é—¨é“ƒï¼ˆGPUæäº¤WQEåˆ°NICï¼‰ï¼Œé€šè¿‡å†™å…¥é—¨é“ƒå¯„å­˜å™¨é€šçŸ¥NICå¤„ç†WQE
        æ”¯æŒæ‰¹å¤„ç†: å¯ä»¥æ‰¹é‡æäº¤å¤šä¸ªWQEï¼Œå‡å°‘é—¨é“ƒè§¦å‘æ¬¡æ•°
        ä¼˜åŠ¿ï¼šæ›´ä½å»¶è¿Ÿ: GPUå¯ä»¥ç«‹å³è§¦å‘NICå¤„ç†WQEï¼Œé€‚åˆä½å»¶è¿Ÿçš„åœºæ™¯ï¼ˆå¦‚æ¨ç†é˜¶æ®µï¼‰ã€‚
             æ›´å¥½çš„æ§åˆ¶: GPUå¯ä»¥ç²¾ç¡®æ§åˆ¶ä½•æ—¶æäº¤WQEï¼Œæ”¯æŒæ‰¹å¤„ç†ç­–ç•¥ï¼Œå‡å°‘é—¨é“ƒå¼€é”€ã€‚
             æ— éœ€CPUè¾…åŠ©: å®Œå…¨ç”±GPUæ§åˆ¶ï¼Œä¸éœ€è¦CPUè¾…åŠ©ã€‚
        åŠ£åŠ¿ï¼šéœ€è¦æ‰¹å¤„ç†: å¦‚æœä¸ä½¿ç”¨æ‰¹å¤„ç†ï¼Œé—¨é“ƒå¼€é”€è¾ƒå¤§ï¼Œéœ€è¦åˆç†è®¾ç½®æ‰¹å¤„ç†å¤§å°ã€‚
             GPUå¼€é”€: GPUéœ€è¦æ˜¾å¼è§¦å‘é—¨é“ƒï¼Œå¢åŠ GPUçº¿ç¨‹çš„å¼€é”€ã€‚

    state->use_async_postsend åœ¨NVSHMEMåˆå§‹åŒ–æ—¶è®¾ç½®: use_async_postsend æ˜¯IBGDAå…¨å±€çŠ¶æ€çš„ä¸€éƒ¨åˆ†ã€‚
    é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®: é€šå¸¸åœ¨NVSHMEMåº“åˆå§‹åŒ–æ—¶æ ¹æ®é…ç½®è®¾ç½®ã€‚è¿è¡Œæ—¶ä¸å¯å˜: ä¸€æ—¦è®¾ç½®ï¼Œåœ¨è¿è¡Œæ—¶ä¸ä¼šæ”¹å˜ã€‚
    å…¸å‹ä½¿ç”¨åœºæ™¯ï¼š
        è®­ç»ƒé˜¶æ®µ: é€šå¸¸ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆuse_async_postsend = trueï¼‰ï¼Œè¿½æ±‚é«˜ååé‡ã€‚
        æ¨ç†é˜¶æ®µ: é€šå¸¸ä½¿ç”¨åŒæ­¥æ¨¡å¼ï¼ˆuse_async_postsend = falseï¼‰ï¼Œè¿½æ±‚ä½å»¶è¿Ÿã€‚
    
    æ³¨æ„: ready_idxçš„å…·ä½“å€¼ï¼Œéœ€è¦ç¨‹åºå‘˜è‡ªå·±è®¾ç½®ï¼Œä¸æ˜¯rdmaåº“è‡ªåŠ¨è®¾ç½®çš„ã€‚
    */
    unsigned long long int* ready_idx =
        (unsigned long long int*)(state->use_async_postsend ? qp->tx_wq.prod_idx : &mvars->tx_wq.ready_head);

    // Wait for prior WQE slots to be filled first
    /*
    å‡½æ•°ç­¾å: atomicCAS(address, compare, val)
    è¯»å– address æŒ‡å‘çš„å€¼ï¼Œå¦‚æœå€¼ç­‰äº compareï¼Œåˆ™å†™å…¥ val å¹¶è¿”å›æ—§å€¼ã€‚å¦‚æœå€¼ä¸ç­‰äº compareï¼Œåˆ™ä¸å†™å…¥ï¼Œè¿”å›å½“å‰å€¼ã€‚è¿”å›å€¼: æ“ä½œå‰çš„æ—§å€¼ã€‚
    åœ¨whileå¾ªç¯ä¹‹åï¼Œå…¶ä»–çº¿ç¨‹/NICæ‰çŸ¥é“æœ‰æ–°çš„WQEéœ€è¦å¤„ç†ã€‚
    */
    while (atomicCAS(ready_idx, base_wqe_idx, new_wqe_idx) != base_wqe_idx);

    // Always post, not in batch
    // åŒæ­¥æ¨¡å¼ä¸­ï¼Œready_idxæŒ‡å‘çš„æ˜¯å·²å‡†å¤‡å¥½æäº¤çš„ WQE ç´¢å¼•ï¼Œä½†æ˜¯å¹¶æ²¡æœ‰çœŸæ­£æäº¤ï¼Œéœ€è¦æ‰‹åŠ¨æäº¤ã€‚
    // å¼‚æ­¥æ¨¡å¼ä¸‹NICè‡ªåŠ¨è½®è¯¢ï¼Œä¸éœ€è¦æ˜¾å¼è§¦å‘é—¨é“ƒã€‚
    if (!state->use_async_postsend) {
        //  æ¯4ä¸ªæ¶ˆæ¯æäº¤ä¸€æ¬¡ï¼ˆæ‰¹å¤„ç†ï¼‰ï¼Œå‡å°‘é—¨é“ƒè§¦å‘æ¬¡æ•°ï¼Œæé«˜æ€§èƒ½ã€‚
        constexpr int kNumRequestInBatch = 4;
        /*
        kAlwaysDoPostSend: æ˜¯å¦æ€»æ˜¯ç«‹å³æäº¤ï¼Œä¸è¿›è¡Œæ‰¹å¤„ç†ã€‚å¦‚æœæ˜¯falseï¼Œåˆ™æ ¹æ®æ‰¹å¤„ç†ç­–ç•¥å†³å®šæ˜¯å¦æäº¤ã€‚
        ç”¨é€”: ç”¨äºéœ€è¦ç«‹å³æäº¤çš„åœºæ™¯ï¼ˆå¦‚æœ€åä¸€ä¸ªæ¶ˆæ¯ï¼‰ã€‚
        message_idx + 1: åŠ 1æ˜¯ä¸ºäº†å¤„ç†â€œç´¢å¼•ä»0å¼€å§‹â€çš„æƒ…å†µï¼Œæ¯4ä¸ªè¿ç»­çš„ message_idx ä¸ºä¸€ç»„æ¶ˆæ¯ï¼Œä¸€èµ·æäº¤ã€‚
        æ¯æ¬¡æäº¤ï¼Œå…·ä½“æäº¤å¤šå°‘ä¸ªwqeå¾—çœ‹ç›¸åŒçš„message_idxä¸­æœ‰å¤šå°‘ä¸ªwqeã€‚å¯¹äºéå…³é”®è·¯å¾„ï¼Œæ‰¹å¤„ç†å¯ä»¥éšè—å»¶è¿Ÿ
        */
        if (kAlwaysDoPostSend or (message_idx + 1) % kNumRequestInBatch == 0)
            ibgda_post_send(qp, new_wqe_idx);
    }
}

__device__ static __forceinline__ void ibgda_write_rdma_write_inl_wqe(
    nvshmemi_ibgda_device_qp_t* qp, const uint32_t* val, uint64_t raddr, __be32 rkey, uint16_t wqe_idx, void** out_wqes, uint32_t imm) {
    ibgda_ctrl_seg_t ctrl_seg;
    struct mlx5_wqe_raddr_seg raddr_seg;
    struct mlx5_wqe_inl_data_seg inl_seg;

    auto* ctrl_seg_ptr = reinterpret_cast<ibgda_ctrl_seg_t*>(out_wqes[0]);
    auto* raddr_seg_ptr = reinterpret_cast<mlx5_wqe_raddr_seg*>(reinterpret_cast<uintptr_t>(ctrl_seg_ptr) + sizeof(*ctrl_seg_ptr));
    auto* inl_seg_ptr = reinterpret_cast<mlx5_wqe_inl_data_seg*>(reinterpret_cast<uintptr_t>(raddr_seg_ptr) + sizeof(*raddr_seg_ptr));
    auto* wqe_data_ptr = reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(inl_seg_ptr) + sizeof(*inl_seg_ptr));

    raddr_seg.raddr = HtoBE64(raddr);
    raddr_seg.rkey = rkey;
    raddr_seg.reserved = 0;

    inl_seg.byte_count = HtoBE32(4 | MLX5_INLINE_SEG);

    // `imm == std::numeric_limits<uint32_t>::max()` means no imm writes
    ctrl_seg = {0};
    ctrl_seg.qpn_ds = HtoBE32((qp->qpn << 8) | 3);
    ctrl_seg.fm_ce_se = MLX5_WQE_CTRL_CQ_UPDATE;
    ctrl_seg.opmod_idx_opcode =
        HtoBE32((wqe_idx << 8) | (imm != std::numeric_limits<uint32_t>::max() ? MLX5_OPCODE_RDMA_WRITE_IMM : MLX5_OPCODE_RDMA_WRITE));
    if (imm != std::numeric_limits<uint32_t>::max())
        ctrl_seg.imm = HtoBE32(imm);

    EP_STATIC_ASSERT(sizeof(*ctrl_seg_ptr) == 16, "sizeof(*ctrl_seg_ptr) == 16");
    EP_STATIC_ASSERT(sizeof(*raddr_seg_ptr) == 16, "sizeof(*raddr_seg_ptr) == 16");
    EP_STATIC_ASSERT(sizeof(*inl_seg_ptr) == 4, "sizeof(*inl_seg_ptr) == 4");
    st_na_relaxed(reinterpret_cast<int4*>(ctrl_seg_ptr), *reinterpret_cast<const int4*>(&ctrl_seg));
    st_na_relaxed(reinterpret_cast<int4*>(raddr_seg_ptr), *reinterpret_cast<const int4*>(&raddr_seg));
    st_na_relaxed(reinterpret_cast<uint32_t*>(inl_seg_ptr), *reinterpret_cast<const uint32_t*>(&inl_seg));
    st_na_relaxed(reinterpret_cast<uint32_t*>(wqe_data_ptr), *reinterpret_cast<const uint32_t*>(val));
}

__device__ static __forceinline__ uint64_t
ibgda_get_lkey_and_rkey(uint64_t laddr, __be32* lkey, uint64_t raddr, int dst_pe, uint64_t* out_raddr, __be32* out_rkey, uint32_t dev_idx) {
    /*
    è¾“å…¥:
        laddr: æœ¬åœ°åœ°å€ï¼ˆä¼šè¢«æ›´æ–°ä¸ºchunkå†…åœ°å€ï¼‰
        raddr: è¿œç¨‹åœ°å€ï¼ˆåŸå§‹åœ°å€ï¼‰
        dst_pe: ç›®æ ‡PE
        dev_idx: NICè®¾å¤‡ç´¢å¼•å·ï¼ˆqp->dev_idxï¼‰
            æ ‡è¯†å½“å‰QPä½¿ç”¨çš„NICè®¾å¤‡
            ç”¨äºæŸ¥æ‰¾è¯¥NICè®¾å¤‡å¯¹åº”çš„å†…å­˜æ³¨å†Œå¯†é’¥
            å› ä¸ºæ¯ä¸ªNICè®¾å¤‡éƒ½æœ‰ç‹¬ç«‹çš„å†…å­˜æ³¨å†Œï¼ˆmemory registrationï¼‰ï¼Œéœ€è¦ä¸åŒçš„lkey/rkey
    è¾“å‡º:
        lkey: æœ¬åœ°chunkçš„è®¿é—®å¯†é’¥
        out_raddr: è½¬æ¢åçš„è¿œç¨‹åœ°å€
        out_rkey: æœ¬åœ°å­˜å‚¨çš„è¿œç¨‹PEçš„chunk raddråœ¨NIC dev_idxä¸­çš„rkey
    è¿”å›å€¼: å½“å‰chunkå¯ä¼ è¾“çš„æœ€å¤§å­—èŠ‚æ•°ï¼ˆå–æœ¬åœ°å’Œè¿œç¨‹chunkå‰©ä½™å¤§å°çš„æœ€å°å€¼ï¼‰
    */
    auto state = ibgda_get_state();
    // è·å–å½“å‰PEçš„å¯¹ç§°å †ï¼ˆsymmetric heapï¼‰åŸºåœ°å€ã€‚ç”¨äºè®¡ç®—åœ°å€ç›¸å¯¹äºå †åŸºå€çš„åç§»é‡ï¼Œä»è€Œå®šä½åˆ°å¯¹åº”çš„chunk
    auto heap_start = reinterpret_cast<uint64_t>(nvshmemi_device_state_d.heap_base);
    /* 
    è·å–CUDAç»Ÿä¸€å†…å­˜ç²’åº¦ï¼ˆä»¥2ä¸ºåº•çš„å¯¹æ•°ï¼‰ï¼Œä¸€èˆ¬ä¸º21ï¼ˆè¡¨ç¤º2^21 = 2MBï¼‰
    ç”¨é€”: ç”¨äºå°†åœ°å€åç§»é‡å³ç§»ï¼Œå¾—åˆ°chunkç´¢å¼•
    å«ä¹‰: å†…å­˜æŒ‰2^log2_cumem_granularityå­—èŠ‚å¯¹é½åˆ’åˆ†ä¸ºchunkã€‚granularity: ç²’åº¦ã€‚
    */
    auto log2_cumem_granularity = state->log2_cumem_granularity;

    // Local key
    /* 
    æœ¬åœ°keyç´¢å¼•è®¡ç®—
    laddr - heap_start: è®¡ç®—ç›¸å¯¹äºå †åŸºå€çš„åç§»é‡
    >> log2_cumem_granularity: å°†åœ°å€åç§»é‡å³ç§»ï¼Œå¾—åˆ°chunkåœ¨PEä¸­çš„ç´¢å¼•
    æ³¨æ„:chunkåœ¨GPUå†…å­˜ä¸­ï¼šchunkæ˜¯GPUå†…å­˜çš„ç‰©ç†åˆ’åˆ†
        æ¯ä¸ªNICéœ€è¦ç‹¬ç«‹æ³¨å†Œï¼šåŒä¸€ä¸ªGPUå†…å­˜chunkï¼Œéœ€è¦åœ¨æ¯ä¸ªNICè®¾å¤‡ä¸Šç‹¬ç«‹æ³¨å†Œï¼Œè·å¾—ä¸åŒçš„lkey/rkey
        è¿™æ˜¯å› ä¸º: 
            ä¸åŒNICæœ‰ä¸åŒçš„PCIeåœ°å€æ˜ å°„;
            ä¸åŒNICæœ‰ä¸åŒçš„è®¿é—®æƒé™å’Œä¸Šä¸‹æ–‡;
            æ¯ä¸ªNICéœ€è¦è‡ªå·±çš„å†…å­˜è®¿é—®å¯†é’¥æ¥éªŒè¯å’Œæˆæƒã€‚
    æ‰€ä»¥ï¼Œæ¯ä¸ªPEçš„lkeysæ•°ç»„éœ€è¦ä¸ºæ¯ä¸ªchunkçš„æ¯ä¸ªNICéƒ½å­˜å‚¨ä¸€ä¸ªå¯†é’¥ã€‚
    * state->num_devices_initialized: ä¹˜ä»¥è®¾å¤‡æ•°é‡ï¼Œå¾—åˆ°æœ¬åœ°keyç´¢å¼•
    + dev_idx: åŠ ä¸Šè®¾å¤‡ç´¢å¼•ï¼Œå¾—åˆ°æœ¬åœ°keyç´¢å¼•
    */
    uint64_t idx = ((laddr - heap_start) >> log2_cumem_granularity) * state->num_devices_initialized + dev_idx;
    /*
    ä»å¸¸é‡å†…å­˜ä¸­è¯»å–å¯¹åº”laddræ‰€åœ¨chunkçš„device_keyç»“æ„ã€‚
    device_keyç»“æ„: åŒ…å«keyï¼ˆlkeyå€¼ï¼‰å’Œnext_addrï¼ˆä¸‹ä¸€ä¸ªchunkçš„èµ·å§‹åœ°å€ï¼‰
    constmem.lkeys: å¸¸é‡å†…å­˜ä¸­çš„æœ¬åœ°å¯†é’¥æ•°ç»„ï¼Œå­˜å‚¨æ‰€æœ‰chunkçš„lkeyä¿¡æ¯
    */ 
    auto device_key = state->constmem.lkeys[idx];
    /*
    è®¡ç®—å½“å‰æœ¬åœ°chunkçš„å‰©ä½™å¤§å°ï¼ˆä»laddråˆ°chunkè¾¹ç•Œçš„å­—èŠ‚æ•°ï¼‰ã€‚
    device_key.next_addr: ä¸‹ä¸€ä¸ªchunkçš„èµ·å§‹åœ°å€ï¼Œå³å½“å‰chunkçš„ç»“æŸåœ°å€
    lchunk_size: å½“å‰chunkä»laddrå¼€å§‹è¿˜èƒ½ä¼ è¾“å¤šå°‘å­—èŠ‚
    ç”¨é€”: ç”¨äºé™åˆ¶å•æ¬¡RDMAæ“ä½œçš„æœ€å¤§ä¼ è¾“å¤§å°ï¼Œä¸èƒ½è¶Šç•Œ
    */
    auto lchunk_size = device_key.next_addr - laddr;
    *lkey = device_key.key;  // å°†è·å–åˆ°çš„lkeyå†™å…¥è¾“å‡ºå‚æ•°

    // Remote key
    uint64_t roffset = raddr - heap_start;

    /*
    è¿œç¨‹keyç´¢å¼•è®¡ç®—
    æ³¨æ„: rkeyéœ€è¦PEç»´åº¦: ä¸åŒPEçš„ç›¸åŒchunkç´¢å¼•å¯¹åº”ä¸åŒçš„ç‰©ç†å†…å­˜ï¼Œéœ€è¦ä¸åŒçš„rkeyã€‚
    å•ä¸ªchunkçš„rkeyçš„å…¨éƒ¨å¤§å°æ˜¯: npes * num_devices_initialized
    */
    idx = ((roffset >> log2_cumem_granularity) * nvshmemi_device_state_d.npes) * state->num_devices_initialized +
        dst_pe * state->num_devices_initialized + dev_idx;
    /*
    è¿™é‡Œå±…ç„¶è¿˜æè¿™ä¹ˆä¸€å‡ºã€‚ğŸ˜‚
    NVSHMEMI_IBGDA_MAX_CONST_RKEYS: å¸¸é‡å†…å­˜ä¸­rkeysæ•°ç»„çš„æœ€å¤§å®¹é‡ã€‚å¸¸é‡å†…å­˜: å®¹é‡æœ‰é™ä½†è®¿é—®é€Ÿåº¦å¿«ï¼Œç”¨äºå­˜å‚¨å¸¸ç”¨çš„rkey
    NVSHMEMI_IBGDA_MAX_CONST_RKEYS å­˜å‚¨ä¸ä¸‹çš„å°±å­˜åœ¨å…¨å±€å†…å­˜ä¸­ã€‚
    */
    if (idx < NVSHMEMI_IBGDA_MAX_CONST_RKEYS) {
        device_key = state->constmem.rkeys[idx];
    } else {
        // globalmem.rkeys æ˜¯å¯ä»¥å­˜å‚¨æ‰€æœ‰çš„rkeyçš„
        device_key = state->globalmem.rkeys[idx - NVSHMEMI_IBGDA_MAX_CONST_RKEYS];
    }
    *out_raddr = reinterpret_cast<uint64_t>(nvshmemi_device_state_d.peer_heap_base_remote[dst_pe]) + roffset;
    *out_rkey = device_key.key;  // æœ¬åœ°å­˜å‚¨çš„è¿œç¨‹PEçš„chunk raddråœ¨NIC dev_idxä¸­çš„rkey

    // Return the minimum of local and remote chunk sizes
    auto rchunk_size = device_key.next_addr - roffset;  // è¿œç¨‹PEçš„è¿™ä¸ªchunkä»raddrå¼€å§‹è¿˜èƒ½ä¼ è¾“å¤šå°‘å­—èŠ‚
    return min(lchunk_size, rchunk_size);  // è¿”å›è¾ƒå°çš„é‚£ä¸ªï¼Œè®©ä¸¤è¾¹éƒ½èƒ½ä¸è·¨chunkä¼ è¾“ã€‚
}

__device__ static __forceinline__ void ibgda_get_rkey(uint64_t addr, int dst_pe, uint64_t* out_raddr, __be32* out_rkey, uint32_t dev_idx) {
    auto state = ibgda_get_state();
    auto heap_start = reinterpret_cast<uint64_t>(nvshmemi_device_state_d.heap_base);

    uint64_t roffset = addr - heap_start;
    uint64_t idx = ((roffset >> state->log2_cumem_granularity) * nvshmemi_device_state_d.npes * state->num_devices_initialized) +
        dst_pe * state->num_devices_initialized + dev_idx;
    nvshmemi_ibgda_device_key_t device_key;
    if (idx < NVSHMEMI_IBGDA_MAX_CONST_RKEYS)
        device_key = state->constmem.rkeys[idx];
    else
        device_key = state->globalmem.rkeys[idx - NVSHMEMI_IBGDA_MAX_CONST_RKEYS];
    *out_raddr = reinterpret_cast<uint64_t>(nvshmemi_device_state_d.peer_heap_base_remote[dst_pe]) + roffset;
    *out_rkey = device_key.key;
}

__device__ static __forceinline__ uint64_t ibgda_reserve_wqe_slots(nvshmemi_ibgda_device_qp_t* qp, uint32_t num_wqes) {
    /*
    qp:        æ¯ä¸ªqpåŒ…å«: å‘é€é˜Ÿåˆ—ï¼ˆTX WQï¼‰ã€å®Œæˆé˜Ÿåˆ—ï¼ˆCQï¼‰ã€ç®¡ç†å˜é‡ï¼ˆmvarsï¼‰ç­‰ã€‚
    um_wqes:   éœ€è¦é¢„ç•™çš„WQEæ•°é‡ï¼Œå³æœ¬æ¬¡æ“ä½œéœ€è¦å¤šå°‘ä¸ªWQEæ§½ä½ã€‚
    qp->mvars: qpçš„ç®¡ç†å˜é‡ï¼ˆmanagement variablesï¼‰ã€‚
               å­˜å‚¨ä½ç½®: GPUå…¨å±€å†…å­˜ï¼ˆæ¯ä¸ªQPæœ‰ç‹¬ç«‹çš„ç®¡ç†å˜é‡ï¼‰ã€‚ä½œç”¨: å­˜å‚¨QPçš„çŠ¶æ€ä¿¡æ¯
    mvars çš„ç±»å‹æ˜¯ nvshmemi_ibgda_device_qp_management_t*
    */
    auto mvars = &qp->mvars;
    /*
    ä½œç”¨: åŸå­åœ°é¢„ç•™num_wqesä¸ªè¿ç»­çš„WQEæ§½ä½
    resv_head: å‘é€é˜Ÿåˆ—ä¸­ä¸‹ä¸€ä¸ªå¯ç”¨çš„WQEç´¢å¼•ï¼ˆç”Ÿäº§è€…æŒ‡é’ˆï¼‰
    è¿”å›å€¼: é¢„ç•™çš„WQEç´¢å¼•èŒƒå›´çš„èµ·å§‹ä½ç½®
    ä¸‹é¢çš„ tx_wq ä¹Ÿæ˜¯ mvars é‡Œçš„ä¸€ä¸ªå­—æ®µã€‚
    struct {
        uint64_t resv_head;    // å‘é€é˜Ÿåˆ—ä¸­ä¸‹ä¸€ä¸ªå¯ç”¨çš„WQEç´¢å¼•ï¼ˆç”Ÿäº§è€…æŒ‡é’ˆï¼‰
        uint64_t prod_idx;     // å·²æäº¤ç»™NICçš„WQEç´¢å¼•ï¼ˆé—¨é“ƒæŒ‡é’ˆï¼‰
        uint64_t ready_head;   // å·²å‡†å¤‡å¥½æäº¤çš„WQEç´¢å¼•
        uint64_t get_head;     // æœ€åä¸€ä¸ª"fetch"æ“ä½œçš„WQEç´¢å¼•
        uint64_t get_tail;     // æœ€åä¸€ä¸ªè¢«è½®è¯¢çš„WQEç´¢å¼•
    } tx_wq;

    mvars->tx_wq.resv_head: resv_headè¡¨ç¤ºä¸‹ä¸€ä¸ªå¯é¢„ç•™çš„WQEç´¢å¼•, ä¹Ÿè¡¨ç¤ºå·²é¢„ç•™çš„WQEæ•°é‡ã€‚
    atomicXXX éƒ½æ˜¯è¿”å›æ—§å€¼ã€‚

    æŒ‡é’ˆå–å­—æ®µç”¨ ->
    å¯¹è±¡æˆ–å¼•ç”¨å–å­—æ®µç”¨ .
    */
    return atomicAdd(reinterpret_cast<unsigned long long*>(&mvars->tx_wq.resv_head), 
                     static_cast<unsigned long long>(num_wqes));
}

__device__ static __forceinline__ void* ibgda_get_wqe_ptr(nvshmemi_ibgda_device_qp_t* qp, uint16_t wqe_idx) {
    /*
    ä½œç”¨: æ ¹æ®WQEç´¢å¼•è®¡ç®—WQEåœ¨å‘é€é˜Ÿåˆ—ä¸­çš„å®é™…å†…å­˜åœ°å€

    è¿”å›å€¼: WQEå†…å­˜åœ°å€æŒ‡é’ˆ

    æ³¨æ„: åŒºåˆ†ä¸‹é¢ä¸¤ç§ tx_wq å­—æ®µï¼š
    1ã€qp->tx_wq: é…ç½®å’Œèµ„æºï¼ˆnwqes, wqe, dbrec ç­‰ï¼‰ï¼Œè¿è¡Œæ—¶ä¸å˜çš„é™æ€å­—æ®µã€‚
    2ã€&qp->mvars->tx_wq: è¿è¡Œæ—¶çŠ¶æ€ï¼ˆresv_head, prod_idx ç­‰ï¼‰ï¼Œè¿è¡Œæ—¶å˜åŒ–çš„åŠ¨æ€å­—æ®µã€‚

    nwqes: Number of WQEsï¼Œå³WQEé˜Ÿåˆ—çš„å¤§å°ï¼ˆå®¹é‡ï¼‰ã€‚nwqes å¿…é¡»æ˜¯2çš„å¹‚æ¬¡æ–¹ï¼ˆå¦‚ 256, 512, 1024, 2048 ç­‰ï¼‰ï¼Œ
    è¿™æ ·å¯ä»¥ç”¨äºåç»­çš„ä½æ©ç å–æ¨¡æ“ä½œï¼Œ2çš„å¹‚æ¬¡æ–¹å¯ä»¥é«˜æ•ˆåœ°ä½¿ç”¨ä½è¿ç®—ä»£æ›¿é™¤æ³•ã€‚
    */
    uint16_t cnt = qp->tx_wq.nwqes;
    /*
    å…¶å®å¾ˆç®€å•ã€‚å½“cntæ˜¯2çš„å¹‚æ¬¡æ–¹æ—¶ï¼Œcnt - 1çš„äºŒè¿›åˆ¶è¡¨ç¤ºæ˜¯å…¨1ã€‚
    å½“ wqe_idx æ¯”cntå°æ—¶ï¼Œwqe_idx & (cnt - 1) çš„ç»“æœå°±æ˜¯ wqe_idx æœ¬èº«ï¼Œä¹Ÿå°±æ˜¯ä½™æ•°éƒ¨åˆ†ã€‚
    å½“ wqe_idx æ¯”cntå¤§æ—¶ï¼Œwqe_idx è¶…å‡ºcntçš„èŒƒå›´é«˜ä½äºŒè¿›åˆ¶å¯¹åº”çš„(cnt - 1) æ˜¯0ï¼Œè¿™éƒ¨åˆ†ä¸0æ±‚ä¸è¿ç®—ï¼Œç»“æœè‚¯å®šæ˜¯0ã€‚
        å°±åªå‰©ä¸‹æ¯”cntå°çš„éƒ¨åˆ†ä¸(cnt - 1)æ±‚ä¸è¿ç®—ï¼Œç»“æœå°±æ˜¯æ¯”cntå°çš„éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯ä½™æ•°éƒ¨åˆ†ã€‚
    */
    uint16_t idx = wqe_idx & (cnt - 1);  // ç¯å½¢ç¼“å†²åŒºå–æ¨¡
    /*
    qp->tx_wq.wqe: WQEé˜Ÿåˆ—çš„å†…å­˜åŸºåœ°å€ï¼ˆvoid*ç±»å‹ï¼‰
    MLX5_SEND_WQE_SHIFT: WQEå¤§å°å¯¹é½çš„ä½ç§»é‡ã€‚å®é™…WQEå¯¹é½çš„å¤§å°æ˜¯(1 << MLX5_SEND_WQE_SHIFT)å­—èŠ‚ï¼Œä¹Ÿå°±æ˜¯(2^MLX5_SEND_WQE_SHIFT)å­—èŠ‚ã€‚
    é€šå¸¸å€¼ä¸º 6ï¼ˆå› ä¸ºMLX5ç¡¬ä»¶è¦æ±‚WQEå¿…é¡»å¯¹é½åˆ°64å­—èŠ‚è¾¹ç•Œï¼‰ï¼Œå¦‚æœWQEå¤§å°æ˜¯128å­—èŠ‚ï¼Œåˆ™ MLX5_SEND_WQE_SHIFT = 7ï¼ˆ2^7 = 128ï¼‰
    idx << MLX5_SEND_WQE_SHIFT: ç›¸å½“äºidx * (2^MLX5_SEND_WQE_SHIFT)ï¼Œä¹Ÿå°±æ˜¯idx * 64ï¼Œå¾—åˆ°idxå¯¹åº”çš„WQEåœ¨WQEé˜Ÿåˆ—ä¸­çš„åç§»é‡ã€‚
    */
    return reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(qp->tx_wq.wqe) + (idx << MLX5_SEND_WQE_SHIFT));
}

__device__ static __forceinline__ void nvshmemi_ibgda_rma_p(
    int* rptr, const int value, int dst_pe, int qp_id, uint32_t imm = std::numeric_limits<uint32_t>::max()) {
    // Get rkey
    // NOTES: the `p` operation will not cross multiple remote chunks
    __be32 rkey;
    uint64_t raddr;
    auto qp = ibgda_get_rc(dst_pe, qp_id);
    ibgda_get_rkey(reinterpret_cast<uint64_t>(rptr), dst_pe, &raddr, &rkey, qp->dev_idx);

    // Write WQEs
    uint64_t base_wqe_idx = ibgda_reserve_wqe_slots(qp, 1);
    void* wqe_ptrs;
    wqe_ptrs = ibgda_get_wqe_ptr(qp, base_wqe_idx);
    ibgda_write_rdma_write_inl_wqe(qp, reinterpret_cast<const uint32_t*>(&value), raddr, rkey, base_wqe_idx, &wqe_ptrs, imm);

    // Submit requests
    ibgda_submit_requests<true>(qp, base_wqe_idx, 1);
}

__device__ static __forceinline__ void ibgda_write_rdma_write_wqe(nvshmemi_ibgda_device_qp_t* qp,
                                                                  uint64_t laddr,
                                                                  __be32 lkey,
                                                                  uint64_t raddr,
                                                                  __be32 rkey,
                                                                  uint32_t bytes,
                                                                  uint16_t wqe_idx,
                                                                  void** out_wqes) {
    /*
    qp,         // Queue PairæŒ‡é’ˆ
    laddr,      // æœ¬åœ°å†…å­˜åœ°å€ï¼ˆå½“å‰chunkï¼‰
    lkey,       // æœ¬åœ°å†…å­˜é”®ï¼ˆå¤§ç«¯åº32ä½ï¼‰
    raddr,      // è¿œç¨‹å†…å­˜åœ°å€ï¼ˆå½“å‰chunkï¼‰
    rkey,       // è¿œç¨‹å†…å­˜é”®ï¼ˆå¤§ç«¯åº32ä½ï¼‰
    bytes,      // ä¼ è¾“å­—èŠ‚æ•°
    wqe_idx,    // WQEç´¢å¼•
    out_wqes    // WQEå†…å­˜åœ°å€æŒ‡é’ˆ
    */
    /*
    ctrl_seg: Control Segmentï¼ˆæ§åˆ¶æ®µï¼‰
    ç±»å‹: ibgda_ctrl_seg_tï¼Œå®é™…ä¸Šæ˜¯ struct mlx5_wqe_ctrl_seg çš„åˆ«å
    å¤§å°: 16å­—èŠ‚ï¼ˆsizeof(int4)ï¼‰
    ä½œç”¨: åŒ…å«WQEçš„æ§åˆ¶ä¿¡æ¯ï¼ˆæ“ä½œç ã€QPç¼–å·ã€æ•°æ®æ®µæ•°é‡ç­‰ï¼‰
    å¯¹é½: __attribute__((__aligned__(8)))ï¼Œ8å­—èŠ‚å¯¹é½
    */
    ibgda_ctrl_seg_t ctrl_seg;
    /*
    raddr_seg: Remote Address Segmentï¼ˆè¿œç¨‹åœ°å€æ®µï¼‰
    ç±»å‹: struct mlx5_wqe_raddr_seg
    å¤§å°: 16å­—èŠ‚ï¼ˆsizeof(int4)ï¼‰
    ä½œç”¨: åŒ…å«è¿œç¨‹å†…å­˜åœ°å€å’Œrkey
    å­—æ®µ: raddrï¼ˆ64ä½åœ°å€ï¼‰ã€rkeyï¼ˆ32ä½å¯†é’¥ï¼‰ã€reservedï¼ˆ32ä½ä¿ç•™å­—æ®µï¼‰
    */
    struct mlx5_wqe_raddr_seg raddr_seg;
    /*
    data_seg: Data Segmentï¼ˆæ•°æ®æ®µï¼‰
    ç±»å‹: struct mlx5_wqe_data_seg
    å¤§å°: 16å­—èŠ‚ï¼ˆsizeof(int4)ï¼‰
    ä½œç”¨: åŒ…å«æœ¬åœ°å†…å­˜åœ°å€ã€lkeyå’Œä¼ è¾“å­—èŠ‚æ•°
    å­—æ®µ: byte_countï¼ˆ32ä½å­—èŠ‚æ•°ï¼‰ã€lkeyï¼ˆ32ä½å¯†é’¥ï¼‰ã€addrï¼ˆ64ä½åœ°å€ï¼‰
    */
    struct mlx5_wqe_data_seg data_seg;

    /*
    ä»¥ä¸Šä¸‰ä¸ªæ®µæ˜¯ç”¨æ¥å£°æ˜WQEæ®µç»“æ„ä½“ã€‚æ¯ä¸ªæ®µéƒ½æ˜¯16å­—èŠ‚ï¼ˆint4çš„å¤§å°ï¼‰ï¼Œè¿™æ˜¯MLX5ç¡¬ä»¶çš„è¦æ±‚ã€‚
    WQEå†…å­˜å¸ƒå±€ï¼ˆ64å­—èŠ‚å¯¹é½ï¼‰ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Control Segment (16å­—èŠ‚)           â”‚ â† ctrl_seg_ptr
    â”‚ Remote Address Segment (16å­—èŠ‚)    â”‚
    â”‚ Data Segment (16å­—èŠ‚)              â”‚
    â”‚ Reserved/Padding (16å­—èŠ‚)          â”‚ â† å¯¹é½åˆ°64å­—èŠ‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    */

    // æŒ‡å‘WQEå†…å­˜ä¸­Control Segmentçš„ä½ç½®ï¼Œè¿™æ˜¯WQEçš„ç¬¬ä¸€ä¸ªæ®µï¼Œä½äºWQEçš„èµ·å§‹ä½ç½®ï¼ˆåç§»0ï¼‰ã€‚
    auto* ctrl_seg_ptr = reinterpret_cast<ibgda_ctrl_seg_t*>(out_wqes[0]);
    /*
    av_seg_ptr: Address Vector SegmentæŒ‡é’ˆ
    æ³¨æ„: è™½ç„¶å˜é‡åæ˜¯ av_seg_ptrï¼Œä½†å®é™…ä¸Šåœ¨RDMA Writeæ“ä½œä¸­ï¼Œè¿™ä¸ªä½ç½®æ˜¯Remote Address Segmentã€‚
    è¿™å¯èƒ½æ˜¯ä¸€ä¸ªå†å²é—ç•™çš„å‘½åï¼ˆåœ¨æŸäº›æ“ä½œä¸­å¯èƒ½æ˜¯Address Vectorï¼‰

    ä¸‹é¢çš„5è¡Œä»£ç å…¶å®ä¸¤è¡Œå°±èƒ½æå®š:
    struct mlx5_wqe_raddr_seg* raddr_seg_ptr = reinterpret_cast<mlx5_wqe_raddr_seg*>(reinterpret_cast<uintptr_t>(ctrl_seg_ptr) + sizeof(*ctrl_seg_ptr));
    struct mlx5_wqe_data_seg* data_seg_ptr = reinterpret_cast<mlx5_wqe_data_seg*>(reinterpret_cast<uintptr_t>(raddr_seg_ptr) + sizeof(*raddr_seg_ptr));
    */
    void* av_seg_ptr = reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(ctrl_seg_ptr) + sizeof(*ctrl_seg_ptr));
    struct mlx5_wqe_raddr_seg* raddr_seg_ptr;
    struct mlx5_wqe_data_seg* data_seg_ptr;

    raddr_seg_ptr = reinterpret_cast<mlx5_wqe_raddr_seg*>(reinterpret_cast<uintptr_t>(av_seg_ptr));
    data_seg_ptr = reinterpret_cast<mlx5_wqe_data_seg*>(reinterpret_cast<uintptr_t>(raddr_seg_ptr) + sizeof(*raddr_seg_ptr));

    /*
    HtoBE64: Host to Big-Endian 64ä½è½¬æ¢å‡½æ•°
    åŠŸèƒ½: å°†64ä½æ•´æ•°ä»ä¸»æœºå­—èŠ‚åºè½¬æ¢ä¸ºå¤§ç«¯åºï¼ˆBig-Endianï¼‰
    åŸå› : InfiniBandç½‘ç»œåè®®ä½¿ç”¨å¤§ç«¯åºï¼Œå¿…é¡»è½¬æ¢
    å®ç°: ä½¿ç”¨PTXæ±‡ç¼–æŒ‡ä»¤ prmt è¿›è¡Œå­—èŠ‚åºè½¬æ¢ã€‚
    Remote Address Segmentç»“æ„:
        struct mlx5_wqe_raddr_seg {
            uint64_t raddr;    // è¿œç¨‹å†…å­˜åœ°å€ï¼ˆ64ä½ï¼Œå¤§ç«¯åºï¼‰
            __be32 rkey;       // è¿œç¨‹å†…å­˜é”®ï¼ˆ32ä½ï¼Œå¤§ç«¯åºï¼‰
            uint32_t reserved; // ä¿ç•™å­—æ®µï¼ˆ32ä½ï¼Œå¿…é¡»ä¸º0ï¼‰
        };  // æ€»å…±16å­—èŠ‚
    */
    raddr_seg.raddr = HtoBE64(raddr);  // 8å­—èŠ‚ï¼Œ64ä½
    raddr_seg.rkey = rkey;             // 4å­—èŠ‚ï¼Œå¤§ç«¯åº32ä½ï¼ˆRemote Address Segmentçš„è¿œç¨‹å¯†é’¥å­—æ®µï¼‰
    raddr_seg.reserved = 0;            // 4å­—èŠ‚ï¼Œä¿ç•™å­—æ®µã€‚å¡«å……ç»“æ„ä½“ï¼Œç¡®ä¿å†…å­˜å¸ƒå±€æ­£ç¡®

    /*
    data_seg.byte_count: å‘Šè¯‰NICè¦ä¼ è¾“å¤šå°‘å­—èŠ‚çš„æ•°æ®
    data_seg.lkey:       æœ¬åœ°å†…å­˜é”®
    data_seg.addr:       æœ¬åœ°å†…å­˜åœ°å€ã€‚å‘Šè¯‰NICæºæ•°æ®åœ¨æœ¬åœ°å†…å­˜ä¸­çš„ä½ç½®
    */
    data_seg.byte_count = HtoBE32(bytes);  // 4å­—èŠ‚ï¼Œå¤§ç«¯åº32ä½
    data_seg.lkey = lkey;                  // 4å­—èŠ‚ï¼Œå¤§ç«¯åº32ä½
    data_seg.addr = HtoBE64(laddr);        // 8å­—èŠ‚ï¼Œ64ä½

    /*
    ibgda_ctrl_seg_t çš„å®šä¹‰æ¥è‡ªäºnvshmemï¼Œè€Œmlx5_wqe_ctrl_segæ¥è‡ªäº:
    https://github.com/linux-rdma/rdma-core/blob/master/providers/mlx5/mlx5dv.h; 
    struct mlx5_wqe_ctrl_seg {
        __be32		opmod_idx_opcode;
        __be32		qpn_ds;
        uint8_t		signature;
        __be16		dci_stream_channel_id;
        uint8_t		fm_ce_se;
        __be32		imm;
    } __attribute__((__packed__)) __attribute__((__aligned__(4)));
    typedef struct mlx5_wqe_ctrl_seg __attribute__((__aligned__(8))) ibgda_ctrl_seg_t;
    */
    /*
    C++11çš„åˆå§‹åŒ–åˆ—è¡¨è¯­æ³•ã€‚å°†ç»“æ„ä½“çš„æ‰€æœ‰å­—æ®µåˆå§‹åŒ–ä¸º0ã€‚ç­‰ä»·äº: memset(&ctrl_seg, 0, sizeof(ctrl_seg))
    åŸå› : ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰æ˜ç¡®çš„åˆå§‹å€¼ï¼Œé¿å…æœªåˆå§‹åŒ–çš„å†…å­˜ã€‚
    */
    ctrl_seg = {0};  // å°†ç»“æ„ä½“åˆå§‹åŒ–ä¸ºå…¨0
    /*
    qp->qpn: Queue Pair Numberï¼ŒQPçš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆ24ä½ï¼‰ã€‚ç”¨äºå‘Šè¯‰NICè¿™ä¸ªWQEå±äºå“ªä¸ªQPã€‚
    qp->qpn << 8: å·¦ç§»8ä½ã€‚QPç¼–å·å­˜å‚¨åœ¨å­—æ®µçš„é«˜24ä½ï¼ˆbit 8-31ï¼‰ã€‚
    | 3: æŒ‰ä½æˆ–æ“ä½œï¼Œå‘Šè¯‰NICè¿™ä¸ªWQEåŒ…å«å¤šå°‘ä¸ªæ®µï¼Œå³è®¾ç½®Data Segmentsã€‚è¡¨ç¤ºæœ‰3ä¸ªæ•°æ®æ®µï¼Œå­˜å‚¨åœ¨å­—æ®µçš„ä½8ä½ï¼ˆbit 0-7ï¼‰ã€‚
    */
    ctrl_seg.qpn_ds = HtoBE32((qp->qpn << 8) | 3);
    /*
    MLX5_WQE_CTRL_CQ_UPDATE: å®Œæˆé˜Ÿåˆ—æ›´æ–°æ ‡å¿—å¸¸é‡ã€‚æŒ‡ç¤ºNICåœ¨å¤„ç†å®Œè¿™ä¸ªWQEåï¼Œæ›´æ–°Completion Queueï¼ˆå®Œæˆé˜Ÿåˆ—ï¼‰ã€‚
                             å€¼é€šå¸¸æ˜¯ 0x1ï¼ˆå…·ä½“å€¼å–å†³äºMLX5é©±åŠ¨å®šä¹‰ï¼‰ã€‚
    ctrl_seg.fm_ce_se: Control Segmentçš„æ ‡å¿—å­—æ®µã€‚æ§åˆ¶WQEå®Œæˆåçš„è¡Œä¸ºã€‚fm: Flow Meterï¼ˆæµè®¡é‡å™¨ï¼‰æ ‡å¿—ã€‚
                       ce: Completion Eventï¼ˆå®Œæˆäº‹ä»¶ï¼‰æ ‡å¿—ã€‚se: Solicited Eventï¼ˆè¯·æ±‚äº‹ä»¶ï¼‰æ ‡å¿—ã€‚
    ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ ‡å¿—: å®Œæˆé€šçŸ¥: å½“WQEå¤„ç†å®Œæˆåï¼ŒNICä¼šåœ¨Completion Queueä¸­å†™å…¥ä¸€ä¸ªå®Œæˆæ¡ç›®
                     è½®è¯¢æœºåˆ¶: GPUå¯ä»¥é€šè¿‡è½®è¯¢Completion Queueæ¥æ£€æŸ¥WQEæ˜¯å¦å®Œæˆ
    */
    ctrl_seg.fm_ce_se = MLX5_WQE_CTRL_CQ_UPDATE;
    /*
    ctrl_seg.opmod_idx_opcode: Control Segmentçš„æ“ä½œç å’Œç´¢å¼•å­—æ®µï¼ˆ32ä½ï¼Œå¤§ç«¯åºï¼‰ã€‚
    wqe_idx: WQEç´¢å¼•ï¼ˆè¾“å…¥å‚æ•°ï¼‰ã€‚uint16_tï¼ˆ16ä½æ— ç¬¦å·æ•´æ•°ï¼‰ã€‚
    MLX5_OPCODE_RDMA_WRITE: RDMAå†™æ“ä½œç å¸¸é‡ã€‚é€šå¸¸æ˜¯ 0x05ï¼ˆå…·ä½“å€¼å–å†³äºMLX5é©±åŠ¨å®šä¹‰ï¼‰ï¼ŒæŒ‡ç¤ºè¿™æ˜¯ä¸€ä¸ªRDMA Writeæ“ä½œã€‚
    opmod_idx_opcodeå­—æ®µï¼ˆ32ä½ï¼‰ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Op Mod (8ä½) â”‚ WQE Index (16ä½) â”‚ Opcode (8ä½) â”‚
    â”‚   bit 24-31  â”‚    bit 8-23     â”‚   bit 0-7    â”‚
    â”‚      0       â”‚   wqe_idx << 8  â”‚ RDMA_WRITE   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    */
    ctrl_seg.opmod_idx_opcode = HtoBE32((wqe_idx << 8) | MLX5_OPCODE_RDMA_WRITE);

    // 3ä¸ªæ®µéƒ½æ˜¯16å­—èŠ‚
    EP_STATIC_ASSERT(sizeof(*ctrl_seg_ptr) == 16, "sizeof(*ctrl_seg_ptr) == 16");
    EP_STATIC_ASSERT(sizeof(*raddr_seg_ptr) == 16, "sizeof(*raddr_seg_ptr) == 16");
    EP_STATIC_ASSERT(sizeof(*data_seg_ptr) == 16, "sizeof(*data_seg_ptr) == 16");
    /*
    ä¸ºä»€ä¹ˆéœ€è¦ st_na_relaxed è€Œä¸æ˜¯æ™®é€šå†™å…¥ï¼š
        st_na_relaxed: Non-Aligned, Relaxed memory orderingã€‚
        ç»•è¿‡L1ç¼“å­˜: ç›´æ¥å†™å…¥å…¨å±€å†…å­˜ï¼Œä¸ç»è¿‡L1ç¼“å­˜ã€‚
        ç«‹å³å¯è§: ç¡®ä¿NICèƒ½ç«‹å³çœ‹åˆ°å†™å…¥çš„æ•°æ®ã€‚
        æ™®é€šå†™å…¥: å¯èƒ½è¢«ç¼“å­˜åœ¨L1ä¸­ï¼ŒNICæ— æ³•çœ‹åˆ°ã€‚
    */
    st_na_relaxed(reinterpret_cast<int4*>(ctrl_seg_ptr), *reinterpret_cast<const int4*>(&ctrl_seg));
    st_na_relaxed(reinterpret_cast<int4*>(raddr_seg_ptr), *reinterpret_cast<const int4*>(&raddr_seg));
    st_na_relaxed(reinterpret_cast<int4*>(data_seg_ptr), *reinterpret_cast<const int4*>(&data_seg));
}

__device__ static __forceinline__ void ibgda_write_empty_recv_wqe(void* out_wqe) {
    auto* data_seg_ptr = reinterpret_cast<struct mlx5_wqe_data_seg*>(out_wqe);
    struct mlx5_wqe_data_seg data_seg;

    // Make the first segment in the WQE invalid, then the entire list will be invalid
    data_seg.byte_count = 0;
    data_seg.lkey = HtoBE64(MLX5_INVALID_LKEY);
    data_seg.addr = 0;

    EP_STATIC_ASSERT(sizeof(mlx5_wqe_data_seg) == sizeof(int4), "Invalid data type length");
    st_na_relaxed(reinterpret_cast<int4*>(data_seg_ptr), *reinterpret_cast<const int4*>(&data_seg));
}

template <bool kAlwaysDoPostSend = false>
__device__ static __forceinline__ void nvshmemi_ibgda_put_nbi_warp(
    uint64_t req_rptr, uint64_t req_lptr, size_t bytes, int dst_pe, int qp_id, int lane_id, int message_idx) {
    /*
    uint64_t req_rptr,      è¿œç¨‹ç›®æ ‡åœ°å€ï¼ˆ64ä½ï¼‰
    uint64_t req_lptr,      æœ¬åœ°æºåœ°å€ï¼ˆ64ä½ï¼‰
    size_t bytes,           è¦ä¼ è¾“çš„å­—èŠ‚æ•°
    int dst_pe,             ç›®æ ‡PEï¼ˆProcessing Elementï¼‰IDï¼Œå³ç›®æ ‡rankã€‚æ³¨æ„: è¿™ä¸ªPEå¯ä»¥æ˜¯GPUï¼Œä¹Ÿå¯ä»¥æ˜¯èŠ‚ç‚¹
    int qp_id,              Queue Pair IDï¼Œåœ¨internode_ll.cuä¸­æ˜¯expert_local_idx
    int lane_id,            warpå†…çš„çº¿ç¨‹IDï¼ˆ0-31ï¼‰
    int message_idx         æ¶ˆæ¯ç´¢å¼•ï¼Œç”¨äºæ‰¹å¤„ç†æ§åˆ¶
    */
    
    // Get lkey and rkey, store them into lanes
    uint32_t num_wqes = 0;          // WQEæ•°é‡è®¡æ•°å™¨ï¼Œåˆå§‹åŒ–ä¸º0ã€‚è®°å½•éœ€è¦å¤šå°‘ä¸ªWQEæ¥å®Œæˆè¿™æ¬¡ä¼ è¾“ã€‚å¦‚æœæ•°æ®è·¨è¶Šå¤šä¸ªå†…å­˜chunkï¼Œå¯èƒ½éœ€è¦å¤šä¸ªWQE
    __be32 my_lkey = 0;             // æœ¬åœ°å†…å­˜é”®ï¼ˆLocal Keyï¼‰ï¼Œè®¿é—®å¯†é’¥ï¼Œå¤§ç«¯åº32ä½ã€‚ç”¨äºRDMAæ“ä½œéªŒè¯æœ¬åœ°å†…å­˜è®¿é—®æƒé™
    uint64_t my_laddr = 0;          // æœ¬åœ°å†…å­˜çš„å®é™…åœ°å€ï¼ˆå¯èƒ½å› chunkè¾¹ç•Œè€Œè°ƒæ•´ï¼‰
    __be32 my_rkey = 0;             // è¿œç¨‹å†…å­˜é”®ï¼ˆRemote Keyï¼‰ï¼Œè®¿é—®å¯†é’¥ï¼Œå¤§ç«¯åº32ä½ã€‚ç”¨äºRDMAæ“ä½œéªŒè¯è¿œç¨‹å†…å­˜è®¿é—®æƒé™
    uint64_t my_raddr = 0;          // è¿œç¨‹å†…å­˜çš„å®é™…åœ°å€ï¼ˆè½¬æ¢ä¸ºNICå¯è®¿é—®çš„åœ°å€ï¼‰
    uint64_t my_chunk_size = 0;     // å½“å‰chunkå¯ä¼ è¾“çš„æœ€å¤§å­—èŠ‚æ•°ï¼ˆå—æœ¬åœ°å’Œè¿œç¨‹chunkå¤§å°é™åˆ¶ï¼‰

    /*
    è·å–æŒ‡å‘ç›®æ ‡PEçš„RCï¼ˆReliable Connectionï¼‰Queue Pairçš„æŒ‡é’ˆã€‚
    åœ¨ internode_ll.cu ä¸­ï¼Œqp_id æ˜¯ expert_local_idxã€‚ä¸åŒä¸“å®¶ä½¿ç”¨ä¸åŒçš„QPï¼Œå®ç°é€šä¿¡è´Ÿè½½åœ¨å¤šæ¡QPä¸Šåˆ†æ•£ï¼Œæé«˜å¹¶è¡Œåº¦ã€‚
    åœ¨ internode.cu ä¸­ï¼Œqp_id æ˜¯ channel_id æˆ– (channel_id + num_channels);
    qp çš„ç±»å‹æ˜¯: nvshmemi_ibgda_device_qp_t *
    */
    auto qp = ibgda_get_rc(dst_pe, qp_id);

    // Decide how many messages (theoretically 3 for maximum)
    auto remaining_bytes = bytes;    // å‰©ä½™å¾…ä¼ è¾“å­—èŠ‚æ•°ï¼Œåˆå§‹åŒ–ä¸ºæ€»å­—èŠ‚æ•°
    while (remaining_bytes > 0) {    // å¾ªç¯ç›´åˆ°æ‰€æœ‰å­—èŠ‚éƒ½åˆ†é…å®Œ
        /* 
        åªæœ‰ç‰¹å®šçº¿ç¨‹è´Ÿè´£è·å–å½“å‰ WQE çš„å¯†é’¥ä¿¡æ¯ï¼Œå¹¶åœ¨åé¢é€šè¿‡ __shfl_sync å°†è·å–çš„ä¿¡æ¯å¹¿æ’­ç»™warpå†…æ‰€æœ‰çº¿ç¨‹ã€‚
        æ¯ä¸ªçº¿ç¨‹éƒ½éœ€è¦çŸ¥é“è‡ªå·±éœ€è¦å¤„ç†çš„chunkä¿¡æ¯ã€‚

        æ³¨æ„: æ¯ä¸ªçº¿ç¨‹åœ¨å¾ªç¯çš„ä¸åŒè¿­ä»£ä¸­è·å–è‡ªå·±è´Ÿè´£çš„chunkçš„lkey/rkeyä¿¡æ¯ã€‚
        */
        if (lane_id == num_wqes) {
            // è·å–lkeyå’Œrkeyï¼Œå¹¶è®¡ç®—å½“å‰chunkçš„æœ€å¤§ä¼ è¾“å¤§å°ï¼Œä¹Ÿå°±æ˜¯å½“å‰chunkçš„å‰©ä½™å¤§å°ï¼Œä¸èƒ½è¶…è¿‡chunkè¾¹ç•Œã€‚
            /*
            æ¯ä¸ªWQEåªèƒ½ä½¿ç”¨ä¸€å¯¹lkey/rkeyã€‚å¦‚æœéœ€è¦ä¼ è¾“çš„æ•°æ®è·¨è¶Šå¤šä¸ªchunkï¼Œéœ€è¦ä½¿ç”¨å¤šä¸ªWQEã€‚
            WQEç»“æ„é™åˆ¶: æ¯ä¸ªWQEçš„Data Segmentåªèƒ½åŒ…å«ï¼š
                ä¸€ä¸ªlkeyï¼ˆæœ¬åœ°å†…å­˜å¯†é’¥ï¼‰
                ä¸€ä¸ªrkeyï¼ˆè¿œç¨‹å†…å­˜å¯†é’¥ï¼‰
                ä¸€ä¸ªè¿ç»­çš„åœ°å€èŒƒå›´
            å¯†é’¥çš„å”¯ä¸€æ€§: æ¯ä¸ªchunkæœ‰è‡ªå·±ç‹¬ç«‹çš„lkey/rkeyï¼Œä¸èƒ½æ··ç”¨ã€‚
            ç¡¬ä»¶è¦æ±‚: RDMAç¡¬ä»¶è¦æ±‚ä¸€æ¬¡æ“ä½œå¿…é¡»åœ¨åŒä¸€ä¸ªå·²æ³¨å†Œçš„å†…å­˜åŒºåŸŸå†…ã€‚
            */
            my_chunk_size = min(remaining_bytes,
                // è¿”å›å€¼: å½“å‰chunkå¯ä¼ è¾“çš„æœ€å¤§å­—èŠ‚æ•°ï¼ˆå–æœ¬åœ°å’Œè¿œç¨‹chunkå‰©ä½™å¤§å°çš„æœ€å°å€¼ï¼‰
                /* æ¯ä¸ªçº¿ç¨‹åœ¨å¾ªç¯çš„ä¸åŒè¿­ä»£ä¸­è·å–è‡ªå·±è´Ÿè´£çš„chunkçš„lkey/rkeyä¿¡æ¯ã€‚
                QPæ˜¯ç‚¹å¯¹ç‚¹è¿æ¥ï¼š
                æ¯ä¸ªQPç»‘å®šåˆ°ç‰¹å®šçš„NICè®¾å¤‡ï¼ˆé€šè¿‡qp->dev_idxï¼‰
                QPå»ºç«‹çš„æ˜¯ï¼šæœ¬åœ°NIC dev_idx â†” è¿œç¨‹NIC dev_idxçš„ç‚¹å¯¹ç‚¹è¿æ¥
                é€šä¿¡å¿…é¡»ä½¿ç”¨å¯¹åº”çš„NICè®¾å¤‡å¯¹ã€‚è¿™æ ·å¯ä»¥ä¿è¯é€šä¿¡ä¸€è‡´æ€§ï¼Œé¿å…NICè®¾å¤‡é”™ä¹±ï¼Œä¹Ÿä½¿å¾—å¯†é’¥åŒ¹é…æ›´æ–¹ä¾¿ã€‚
                */
                ibgda_get_lkey_and_rkey(
                    my_laddr = req_lptr,    // è¾“å…¥ï¼šæœ¬åœ°åœ°å€ã€‚req_lptr: ç”¨åœ¨å¾ªç¯ä¸­ï¼Œå¸®åŠ©è®¡ç®—æ¯ä¸ªçº¿ç¨‹è´Ÿè´£çš„æ•°æ®çš„æœ¬åœ°åœ°å€ã€‚
                    &my_lkey,               // è¾“å‡ºï¼šæœ¬åœ°å†…å­˜é”®ã€‚
                    req_rptr,               // è¾“å…¥ï¼šç”¨åœ¨å¾ªç¯ä¸­ï¼Œå¸®åŠ©è®¡ç®—æ¯ä¸ªçº¿ç¨‹è´Ÿè´£çš„æ•°æ®çš„è¿œç¨‹åœ°å€ã€‚
                    dst_pe,                 // è¾“å…¥ï¼šç›®æ ‡PE
                    &my_raddr,              // è¾“å‡ºï¼šå½“å‰çº¿ç¨‹è¦å®é™…å†™å…¥åˆ°è¿œç¨‹PEçš„å†…å­˜çš„åœ°å€
                    &my_rkey,               // è¾“å‡ºï¼šè¿œç¨‹å†…å­˜é”®
                    qp->dev_idx             // è¾“å…¥ï¼šè®¾å¤‡ç´¢å¼•ã€‚æŒ‡çš„æ˜¯å½“å‰PEå’Œè¿œç¨‹PEçš„ NIC è®¾ç½®ç´¢å¼•ã€‚æ¯ä¸ª NIC è®¾å¤‡éƒ½æœ‰å”¯ä¸€çš„ç´¢å¼•ï¼Œç”¨äºæ ‡è¯†å®ƒåœ¨ PCIe æ€»çº¿ä¸Šçš„ä½ç½®ã€‚
                )
            );
        }

        // Move one more message
        // æ¯ä¸ªçº¿ç¨‹éƒ½éœ€è¦çŸ¥é“è‡ªå·±éœ€è¦å¤„ç†çš„chunkä¿¡æ¯ã€‚
        auto chunk_size = __shfl_sync(0xffffffff, my_chunk_size, static_cast<int>(num_wqes));
        remaining_bytes -= chunk_size;  // å‡å»å·²åˆ†é…çš„chunkå¤§å°
        // æ¯æ¬¡å¾ªç¯åï¼Œreq_lptrå’Œreq_rptréƒ½å‘å‰ç§»åŠ¨chunk_sizeå­—èŠ‚ï¼Œç¡®ä¿ä¸‹ä¸€ä¸ªWQEå¤„ç†ä¸‹ä¸€ä¸ªchunkçš„æ•°æ®ã€‚
        req_lptr += chunk_size;         // æ›´æ–°æœ¬åœ°åœ°å€æŒ‡é’ˆ
        req_rptr += chunk_size;         // æ›´æ–°è¿œç¨‹åœ°å€æŒ‡é’ˆ
        /*
        å¦‚æœç¦»å¼€whileå¾ªç¯ånum_wqes > 1ï¼Œåˆ™å¿…ç„¶æœ‰è·¨chunkçš„æƒ…å†µã€‚
        è¿™æ˜¯å› ä¸º min è¦ä¹ˆé€‰æ‹©remaining_bytesè¦ä¹ˆé€‰æ‹©å½“å‰chunkå¯ä¼ è¾“çš„æœ€å¤§å­—èŠ‚æ•°ã€‚
        å¦‚æœé€‰æ‹©remaining_bytesï¼Œé‚£ä¹ˆremaining_bytes -= chunk_sizeå°±ä¼šè®©remaining_bytesä¸º0ï¼Œå¾ªç¯å®Œæˆï¼Œnum_wqesæ˜¯1ï¼›
        å¦‚æœé€‰æ‹©å½“å‰chunkå¯ä¼ è¾“çš„æœ€å¤§å­—èŠ‚æ•°ï¼Œé‚£ä¹ˆremaining_bytes -= chunk_sizeæ‰§è¡Œå remaining_bytes>0ï¼Œå¾ªç¯ç»§ç»­ï¼Œnum_wqeså°±ä¼šå¤§äº1ã€‚
        */
        ++num_wqes;                     // WQEè®¡æ•°å™¨åŠ 1
    }
    EP_DEVICE_ASSERT(num_wqes <= 32);   // æœ€å¤š32ä¸ªWQEï¼ˆwarpå¤§å°é™åˆ¶ï¼‰

    // Process WQE
    uint64_t base_wqe_idx = 0;  // åŸºç¡€WQEç´¢å¼•
    if (lane_id == 0)
        // åŸå­åœ°é¢„ç•™num_wqesä¸ªè¿ç»­çš„WQEæ§½ä½ã€‚ç”¨äºåç»­çš„WQEåˆ†é…ã€‚
        // base_wqe_idx: é¢„ç•™çš„WQEç´¢å¼•èŒƒå›´çš„èµ·å§‹ä½ç½®ã€‚
        base_wqe_idx = ibgda_reserve_wqe_slots(qp, num_wqes);
    base_wqe_idx = __shfl_sync(0xffffffff, base_wqe_idx, 0);
    if (lane_id < num_wqes) {
        /*
        æ¯ä¸ªçº¿ç¨‹æ ¹æ® lane_id è®¡ç®—è‡ªå·±è´Ÿè´£çš„WQEç´¢å¼•ã€‚æ¯ä¸ªçº¿ç¨‹è´Ÿè´£å†™å…¥ä¸€ä¸ª WQEã€‚
        ä¸€ä¸ª WQE å¤„ç†ä¸€ä¸ª chunk çš„æ•°æ®ã€‚
        wqe_idx: å½“å‰çº¿ç¨‹è´Ÿè´£çš„WQEç´¢å¼•ã€‚è¿™ä¸ªç´¢å¼•æ˜¯æŒ‡qpçš„tx_wqä¸­çš„WQEç´¢å¼•ã€‚
        */
        auto wqe_idx = base_wqe_idx + lane_id;
        /*
        æ ¹æ®WQEç´¢å¼•è®¡ç®—WQEåœ¨å‘é€é˜Ÿåˆ—ä¸­çš„å®é™…å†…å­˜åœ°å€ã€‚
        qp->tx_wq.wqe: WQEå‘é€é˜Ÿåˆ—çš„å†…å­˜åŸºåœ°å€ï¼ˆvoid*ç±»å‹ï¼‰
        qp->tx_wq.nwqes: WQEå‘é€é˜Ÿåˆ—çš„å¤§å°ï¼ˆæ•°é‡ï¼‰
        ç„¶åç¯å½¢ç¼“å†²åŒºå–æ¨¡å¾—åˆ°ã€‚
        */
        auto wqe_ptr = ibgda_get_wqe_ptr(qp, wqe_idx);
        /*
        qp,              // Queue PairæŒ‡é’ˆ
        my_laddr,        // æœ¬åœ°å†…å­˜åœ°å€ï¼ˆå½“å‰chunkï¼‰
        my_lkey,         // æœ¬åœ°å†…å­˜é”®
        my_raddr,        // è¿œç¨‹å†…å­˜åœ°å€ï¼ˆå½“å‰chunkï¼‰
        my_rkey,         // è¿œç¨‹å†…å­˜é”®
        my_chunk_size,   // ä¼ è¾“å­—èŠ‚æ•°
        wqe_idx,         // WQEç´¢å¼•
        &wqe_ptr         // WQEå†…å­˜åœ°å€æŒ‡é’ˆ
        */
        ibgda_write_rdma_write_wqe(qp, my_laddr, my_lkey, my_raddr, my_rkey, my_chunk_size, wqe_idx, &wqe_ptr);
    }
    __syncwarp();  // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ WQE å†™å…¥æœ¬åœ° SQï¼ˆSend Queueï¼‰ï¼Œå’Œè¿è¡ŒæˆåŠŸåå†™å…¥ CQ çš„å›è°ƒã€‚

    // Submit
    if (lane_id == 0)
        ibgda_submit_requests<kAlwaysDoPostSend>(qp, base_wqe_idx, num_wqes, message_idx);
    __syncwarp();
}

__device__ static __forceinline__ void ibgda_write_amo_add_wqe(nvshmemi_ibgda_device_qp_t* qp,
                                                               const int& value,
                                                               uint64_t laddr,
                                                               __be32 lkey,
                                                               uint64_t raddr,
                                                               __be32 rkey,
                                                               uint16_t wqe_idx,
                                                               void** out_wqes) {
    ibgda_ctrl_seg_t ctrl_seg = {0};
    struct mlx5_wqe_raddr_seg raddr_seg;
    struct mlx5_wqe_atomic_seg atomic_seg_1;
    struct mlx5_wqe_data_seg data_seg;

    auto ctrl_seg_ptr = reinterpret_cast<ibgda_ctrl_seg_t*>(out_wqes[0]);
    auto raddr_seg_ptr = reinterpret_cast<mlx5_wqe_raddr_seg*>(reinterpret_cast<uintptr_t>(ctrl_seg_ptr) + sizeof(*ctrl_seg_ptr));
    auto atomic_seg_ptr = reinterpret_cast<mlx5_wqe_atomic_seg*>(reinterpret_cast<uintptr_t>(raddr_seg_ptr) + sizeof(*raddr_seg_ptr));
    auto data_seg_ptr = reinterpret_cast<mlx5_wqe_data_seg*>(reinterpret_cast<uintptr_t>(atomic_seg_ptr) + sizeof(*atomic_seg_ptr));

    raddr_seg.raddr = HtoBE64(raddr);
    raddr_seg.rkey = rkey;
    raddr_seg.reserved = 0;

    // NOTES: `0x08000000` means `IBGDA_4_BYTE_EXT_AMO_OPMOD`
    ctrl_seg.opmod_idx_opcode = HtoBE32(MLX5_OPCODE_ATOMIC_MASKED_FA | (wqe_idx << 8) | 0x08000000);
    auto atomic_32_masked_fa_seg = reinterpret_cast<ibgda_atomic_32_masked_fa_seg_t*>(&atomic_seg_1);
    atomic_32_masked_fa_seg->add_data = HtoBE32(value);
    atomic_32_masked_fa_seg->field_boundary = 0;

    ctrl_seg.qpn_ds = HtoBE32((qp->qpn << 8) | 4);
    ctrl_seg.fm_ce_se = MLX5_WQE_CTRL_CQ_UPDATE;

    data_seg.byte_count = HtoBE32(sizeof(int));
    data_seg.lkey = lkey;
    data_seg.addr = HtoBE64(laddr);

    EP_STATIC_ASSERT(sizeof(*ctrl_seg_ptr) == sizeof(int4), "Invalid vectorization");
    EP_STATIC_ASSERT(sizeof(*raddr_seg_ptr) == sizeof(int4), "Invalid vectorization");
    EP_STATIC_ASSERT(sizeof(*atomic_seg_ptr) == sizeof(int4), "Invalid vectorization");
    EP_STATIC_ASSERT(sizeof(*data_seg_ptr) == sizeof(int4), "Invalid vectorization");
    st_na_relaxed(reinterpret_cast<int4*>(ctrl_seg_ptr), *reinterpret_cast<int4*>(&ctrl_seg));
    st_na_relaxed(reinterpret_cast<int4*>(raddr_seg_ptr), *reinterpret_cast<int4*>(&raddr_seg));
    st_na_relaxed(reinterpret_cast<int4*>(atomic_seg_ptr), *reinterpret_cast<int4*>(&atomic_seg_1));
    st_na_relaxed(reinterpret_cast<int4*>(data_seg_ptr), *reinterpret_cast<int4*>(&data_seg));
}

__device__ __forceinline__ void nvshmemi_ibgda_amo_nonfetch_add(
    void* rptr, const int& value, int pe, int qp_id, bool is_local_copy = false) {
    if (is_local_copy) {
        atomicAdd(static_cast<unsigned long long*>(rptr), value);
    } else {
        nvshmemi_ibgda_device_qp_t* qp = ibgda_get_rc(pe, qp_id);

        __be32 rkey;
        uint64_t raddr;
        ibgda_get_rkey(reinterpret_cast<uint64_t>(rptr), pe, &raddr, &rkey, qp->dev_idx);

        uint64_t my_wqe_idx = ibgda_reserve_wqe_slots(qp, 1);
        void* wqe_ptrs = ibgda_get_wqe_ptr(qp, my_wqe_idx);

        ibgda_write_amo_add_wqe(qp, value, reinterpret_cast<uint64_t>(qp->ibuf.buf), qp->ibuf.lkey, raddr, rkey, my_wqe_idx, &wqe_ptrs);

        ibgda_submit_requests<true>(qp, my_wqe_idx, 1);
    }
}

__device__ __forceinline__ uint64_t nvshmemi_get_p2p_ptr(const uint64_t& ptr, const int& rank, const int& dst_rank) {
    // Local rank, no need for mapping
    if (rank == dst_rank)
        return ptr;
    /*
    peer_heap_base_p2p
    æ•°æ®ç±»å‹: void **ï¼ˆæŒ‡é’ˆæ•°ç»„ï¼‰
    å«ä¹‰: æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯æŒ‡å‘nvshmemé›†ç¾¤ä¸­çš„å„ä¸ªranké€šè¿‡ P2Pï¼ˆPeer-to-Peerï¼‰è®¿é—®çš„ PE å †åŸºåœ°å€çš„æŒ‡é’ˆï¼Œç”¨äº GPU é—´ç›´æ¥è®¿é—®ã€‚
         peer_heap_base_p2pè¡¨ç¤ºçš„åªæ˜¯å½“å‰rankå¯¹æ•´ä¸ªå¤šæœºå¤šå¡é›†ç¾¤ä¸Šçš„å„ä¸ªrankçš„æ˜¯å¦å¯ä»¥è¿›è¡Œp2pçš„ä¿¡æ¯ï¼Œ
         å¦‚æœå¯¹åº”dst_rankè¿”å›çš„peer_baseæ˜¯0ï¼Œå°±è¯´æ˜å½“å‰rankä¸dst_rankä¸èƒ½p2pè®¿é—®ï¼Œä¹Ÿå°±æ˜¯ä¸åœ¨åŒä¸€ä¸ªnodeä¸Šã€‚
         å¦‚æœå¯¹åº”dst_rankè¿”å›çš„peer_baseä¸æ˜¯0ï¼Œå°±è¯´æ˜å¯ä»¥p2pè®¿é—®ï¼Œåœ¨åŒä¸€ä¸ªnodeä¸Šã€‚è®°å½•çš„å°±æ˜¯è¿™ä¸ªdst_rankçš„heap_baseåœ°å€ã€‚
    æ³¨æ„: åœ¨æ¯ä¸ªrankä¸­çš„nvshmemi_device_state_d.peer_heap_base_p2pè®°å½•çš„ä¿¡æ¯æ˜¯ä¸ä¸€æ ·çš„ã€‚
    ä½œç”¨:
        - å­˜å‚¨å¯é€šè¿‡ P2P è®¿é—®çš„ PE çš„å †åŸºåœ°å€
        - ç”¨äº P2P è®¿é—®ï¼šå½“ä¸¤ä¸ª GPU æ”¯æŒ P2P æ—¶ï¼Œç›´æ¥ä½¿ç”¨è¯¥åœ°å€è¿›è¡Œè®¿é—®
        - åœ¨åŠ¨æ€ VMM æ¨¡å¼ä¸‹ï¼Œå¯èƒ½ä½¿ç”¨è™šæ‹Ÿåœ°å€æ˜ å°„ï¼Œè€Œéå®é™…ç‰©ç†åœ°å€
    æ•°ç»„ç»“æ„:
        - å…ƒç´ æ•°é‡ï¼šnpesã€‚npesï¼šå‚ä¸ NVSHMEM é€šä¿¡çš„ PE æ€»æ•°ï¼ŒåŒ…å«å¤šæœºå¤šå¡çš„æ‰€æœ‰PEã€‚
        - æ¯ä¸ªå…ƒç´ ï¼švoid *ï¼ˆ8 å­—èŠ‚ï¼Œ64 ä½ç³»ç»Ÿï¼‰ï¼Œè¡¨ç¤ºè¯¥PEçš„P2På¯è®¿é—®å †åŸºåœ°å€ã€‚
        - æ€»å¤§å°ï¼šnpes * sizeof(void *) = npes * 8 å­—èŠ‚
    æ•°æ®æ’åˆ—æ–¹å¼:
        - è¿ç»­æ•°ç»„ï¼Œç´¢å¼•å¯¹åº” PE ID
        - peer_heap_base_p2p[i] å­˜å‚¨ PE i çš„ P2P å¯è®¿é—®å †åŸºåœ°å€
        - å¦‚æœ PE i ä¸æ”¯æŒ P2Pï¼Œè¯¥å…ƒç´ å¯èƒ½ä¸º 0
        - æœ¬åœ° PE çš„åœ°å€ï¼špeer_heap_base_p2p[mype] = heap_base

    è¡¥å……:
        nvshmemi_device_state_d.peer_heap_base_p2p[dst_pe] å’Œ nvshmemi_device_state_d.peer_heap_base_remote[dst_pe]
        æŒ‡å‘çš„éƒ½æ˜¯rank dst_peåœ¨æ•´ä¸ªnvshmemçš„PGASä½“ç³»ä¸‹çš„å¯¹ç§°å†…å­˜çš„èµ·å§‹åœ°å€ã€‚
        åŒºåˆ«: peer_heap_base_p2p[dst_pe] è¡¨ç¤ºå½“å‰ rank èƒ½é€šè¿‡ GPU P2Pï¼ˆå¦‚ NVLink/PCIe peer accessï¼‰ç›´æ¥è®¿é—®çš„ç›®æ ‡ rank çš„ heap åŸºå€ï¼ˆä¸å¯ P2P æ—¶ä¸º 0ï¼‰ï¼›
             peer_heap_base_remote[dst_pe] åˆ™æ˜¯ç”¨äº RDMA/IBGDA ç­‰è·¨èŠ‚ç‚¹è¿œç¨‹è®¿é—®çš„è¿œç«¯åŸºå€ï¼Œä¾›æ„é€ è¿œç«¯ raddr ä½¿ç”¨ã€‚
    */
    auto peer_base = __ldg(reinterpret_cast<uint64_t*>(nvshmemi_device_state_d.peer_heap_base_p2p) + dst_rank);

    // RDMA connected
    if (peer_base == 0)
        return 0;

    // NVLink P2P is enabled
    /*
    heap_base
    æ•°æ®ç±»å‹ï¼š void *ï¼ˆæŒ‡é’ˆï¼‰
    å«ä¹‰ï¼š æŒ‡å‘å½“å‰ PEï¼ˆProcessing Elementï¼‰çš„å¯¹ç§°å †ï¼ˆsymmetric heapï¼‰åŸºåœ°å€ã€‚
          å°±æ˜¯PGASçš„PEä¹‹é—´é€šè¿‡å¯¹ç§°å†…å­˜ï¼ˆSymmetric Memoryï¼‰ è¿›è¡Œé€šä¿¡å’Œæ•°æ®å…±äº«ï¼Œè¿™ç±»å†…å­˜ä»ä½äºGPUå†…å­˜ä¸­çš„â€œå¯¹ç§°å †ï¼ˆSymmetric Heapï¼‰â€
    ä½œç”¨ï¼š
        - ä½œä¸ºæœ¬åœ°å †çš„èµ·å§‹åœ°å€ï¼Œç”¨äºè®¡ç®—å †å†…åç§»
        - åœ¨è®¾å¤‡ç«¯ç”¨äºåœ°å€è½¬æ¢ï¼šå°†æœ¬åœ°åœ°å€è½¬æ¢ä¸ºè¿œç¨‹ PE çš„å¯¹åº”åœ°å€
        - ç”¨äºåˆ¤æ–­åœ°å€æ˜¯å¦åœ¨å †èŒƒå›´å†…
    åˆ†é…æ–¹å¼ï¼š
        - é€šè¿‡ cudaMallocã€cuMemAddressReserve æˆ–å…±äº«å†…å­˜ç­‰æ–¹å¼åˆ†é…
        - å¤§å°ç”± heap_size å†³å®šï¼Œé€šå¸¸å¯¹é½åˆ°å†…å­˜ç²’åº¦ï¼ˆå¦‚ 2MBï¼‰

    åœ°å€ptrç›¸å¯¹äºå½“å‰rankçš„heap_baseçš„åç§»é‡ï¼šptr - reinterpret_cast<uint64_t>(nvshmemi_device_state_d.heap_base)
    åŠ ä¸Špeer_baseï¼Œæœ€ç»ˆè¿”å›çš„å°±æ˜¯ptrå¯¹åº”çš„åœ¨rank dst_rankçš„heap_baseä¸­çš„åœ°å€ã€‚
    */
    return peer_base + (ptr - reinterpret_cast<uint64_t>(nvshmemi_device_state_d.heap_base));
}

// This is a simplified version of NVSHMEM's `ibgda_poll_cq`.
// Note that this implementation does not guarantee thread safety,
// so we must ensure that no other threads are concurrently using the same QP.
/*
è¿™æ˜¯ NVSHMEM çš„ ibgda_poll_cq çš„ç®€åŒ–ç‰ˆæœ¬ã€‚
æ³¨æ„ï¼šæ­¤å®ç°ä¸ä¿è¯çº¿ç¨‹å®‰å…¨ï¼Œå› æ­¤å¿…é¡»ç¡®ä¿æ²¡æœ‰å…¶ä»–çº¿ç¨‹å¹¶å‘ä½¿ç”¨åŒä¸€ä¸ª QPã€‚
*/
__device__ static __forceinline__ void ibgda_poll_cq(nvshmemi_ibgda_device_cq_t* cq, uint64_t idx) {
    /*
    nvshmemi_ibgda_device_cq_t* cq,  // æŒ‡å‘å®Œæˆé˜Ÿåˆ—ï¼ˆCompletion Queueï¼‰çš„æŒ‡é’ˆ
    uint64_t idx                     // éœ€è¦ç­‰å¾…å®Œæˆçš„æœ€å¤§ WQE ç´¢å¼•ï¼ˆå®é™…ç»´æŠ¤çš„æ˜¯ index + 1ï¼‰
    */

    /*
    cqe64ï¼šç±»å‹ä¸º mlx5_cqe64*ï¼ŒæŒ‡å‘ 64 å­—èŠ‚ CQE çš„æ•°ç»„çš„æŒ‡é’ˆã€‚
    cq->cqeï¼šå®Œæˆé˜Ÿåˆ—æ¡ç›®ï¼ˆCompletion Queue Entryï¼‰æ•°ç»„çš„åŸºåœ°å€
    mlx5_cqe64ï¼šMellanox MLX5 çš„ 64 å­—èŠ‚ CQE ç»“æ„ä½“
    å°† cq->cqe è½¬æ¢ä¸º mlx5_cqe64*ï¼Œç”¨äºè®¿é—®ç¡¬ä»¶ CQE

    cqç»“æ„ä½“ï¼ˆç®€åŒ–ï¼‰
    typedef struct {
        void* cqe;             // CQEæ•°ç»„åŸºåœ°å€
        uint32_t ncqes;        // CQEæ•°é‡
        uint64_t* cons_idx;    // æ¶ˆè´¹è€…ç´¢å¼•æŒ‡é’ˆï¼ˆè½¯ä»¶ç»´æŠ¤ï¼‰ã€‚å·²è½®è¯¢å®Œæˆçš„æœ€å¤§ WQE ç´¢å¼• + 1ã€‚
    } nvshmemi_ibgda_device_cq_t;
    */
    const auto cqe64 = static_cast<mlx5_cqe64*>(cq->cqe);
    /*
    ncqes = Number of Completion Queue Entriesï¼ˆå®Œæˆé˜Ÿåˆ—æ¡ç›®æ•°é‡ï¼‰
    è¿™æ˜¯ CQ æ•°ç»„çš„å¤§å°ï¼Œå³å¯ä»¥å­˜å‚¨å¤šå°‘ä¸ª CQEï¼Œæ˜¯ CQ çš„å®¹é‡ï¼ˆå›ºå®šå€¼ï¼‰
    ç”¨äºæº¢å‡ºå®‰å…¨æ¯”è¾ƒï¼Œå› ä¸º CQ æ˜¯ç¯å½¢ç¼“å†²åŒº
    é€šå¸¸ä¸º 2 çš„å¹‚ï¼š256ã€512ã€1024 ç­‰
    */
    const uint32_t ncqes = cq->ncqes;
    // CTA çº§åˆ«å†…å­˜å±éšœã€‚acquireåä¸åˆ°å‰ã€‚é˜²æ­¢åœ¨è¯»å– CQ çŠ¶æ€å‰ï¼Œå†…å­˜æ“ä½œè¢«é‡æ’åºã€‚ç¡®ä¿åç»­è¯»å–èƒ½çœ‹åˆ°æœ€æ–°çš„ç¡¬ä»¶çŠ¶æ€
    memory_fence_cta();
    // *cq->cons_idxï¼šè½¯ä»¶ç»´æŠ¤çš„æ¶ˆè´¹è€…ç´¢å¼•ï¼ˆå·²è½®è¯¢å®Œæˆçš„æœ€å¤§ WQE ç´¢å¼• + 1ï¼‰ï¼Œå¦‚æœè¯¥å€¼å¤§äºç­‰äºidxï¼Œè¯´æ˜idxå¯¹åº”çš„WQEå·²ç»å®Œæˆæ¶ˆè´¹ã€‚
    if (*cq->cons_idx >= idx)
        return;
    // NOTES: this while loop is part of do-while below.
    // `wqe_counter` is the HW consumer index. However, we always maintain `index + 1`.
    // To be able to compare with the index, we need to use `wqe_counter + 1`.
    // Because `wqe_counter` is `uint16_t`, it may be overflow. Still, we know for
    // sure that if `idx - wqe_counter - 1 < ncqes`, `wqe_counter + 1 is less than
    // idx, and thus we need to wait. We don't need to wait when `idx == wqe_counter + 1`
    // That's why we use `- 2` here to make this case overflow.
    /*
    æ³¨æ„ï¼šè¿™ä¸ª while å¾ªç¯æ˜¯ä¸‹é¢ do-while çš„ä¸€éƒ¨åˆ†ã€‚
    wqe_counter æ˜¯ç¡¬ä»¶æ¶ˆè´¹è€…ç´¢å¼•ã€‚ä½†æˆ‘ä»¬æ€»æ˜¯ç»´æŠ¤ index + 1ã€‚
    ä¸ºäº†èƒ½å¤Ÿä¸ç´¢å¼•è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ wqe_counter + 1ã€‚
    å› ä¸º wqe_counter æ˜¯ uint16_tï¼Œå¯èƒ½ä¼šæº¢å‡ºã€‚
    ä½†æˆ‘ä»¬çŸ¥é“ï¼Œå¦‚æœ idx - wqe_counter - 1 < ncqesï¼Œåˆ™ wqe_counter + 1 å°äº idxï¼Œå› æ­¤éœ€è¦ç­‰å¾…ã€‚
    å½“ idx == wqe_counter + 1 æ—¶ä¸éœ€è¦ç­‰å¾…ã€‚æ­¤æ—¶ idx - wqe_counter - 1 = 0ï¼Œ idx - wqe_counter - 2 = -1
    è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ - 2 æ¥ä½¿è¿™ç§æƒ…å†µæº¢å‡ºã€‚æ­¤æ—¶å°±æ˜¯è´Ÿæ•°ï¼ˆ-1ï¼‰ï¼Œä½†æ˜¯uint16_tæ˜¯æ— ç¬¦å·çš„ï¼Œ
    æ‰€ä»¥è´Ÿæ•°ï¼ˆ-1ï¼‰å°±ä¼šå˜æˆ65535ï¼Œåè€Œæ˜¯uint16_tèƒ½è¡¨ç¤ºçš„æœ€å¤§çš„æ­£æ•°ï¼Œæ­¤æ—¶å°±è‚¯å®šå¤§äºç­‰äºuint16_tæ ¼å¼çš„ncqesã€‚
    
    ä¸èƒ½ç›´æ¥ç”¨ idx < wqe_counter çš„åŸå› :
        æº¢å‡ºé—®é¢˜ï¼šwqe_counter æ˜¯ 16 ä½ï¼Œä¼šä» 65535 å›ç»•åˆ° 0
        ç±»å‹ä¸åŒ¹é…ï¼šidx æ˜¯ 64 ä½ï¼Œwqe_counter æ˜¯ 16 ä½
        é”™è¯¯åˆ¤æ–­ï¼šæº¢å‡ºåç›´æ¥æ¯”è¾ƒä¼šå¾—å‡ºé”™è¯¯ç»“è®º
    
    åœºæ™¯1ï¼šæ­£å¸¸æƒ…å†µï¼ˆæ— æº¢å‡ºï¼‰
        wqe_counter = 100  (å·²æ¶ˆè´¹ç´¢å¼• 0-99)
        idx = 50           (éœ€è¦ç­‰å¾…ç´¢å¼• 49)
        ç›´æ¥æ¯”è¾ƒ: idx < wqe_counter â†’ 50 < 100 â†’ true âœ“
        ç»“è®º: ç´¢å¼•49å·²å®Œæˆï¼Œä¸éœ€è¦ç­‰å¾… âœ“
    
    åœºæ™¯2ï¼šæº¢å‡ºæƒ…å†µï¼ˆå…³é”®é—®é¢˜ï¼‰
        å‡è®¾ wqe_counter ä» 65535 æº¢å‡ºåˆ° 0
        wqe_counter = 0    (å®é™…ä¸Šå·²æ¶ˆè´¹äº†ç´¢å¼• 0-65534ï¼Œæº¢å‡ºåé‡æ–°å¼€å§‹)
        idx = 100          (éœ€è¦ç­‰å¾…ç´¢å¼• 99)
        ç›´æ¥æ¯”è¾ƒ: idx < wqe_counter â†’ 100 < 0 â†’ false âœ—
        ç»“è®º: é”™è¯¯ï¼å®é™…ä¸Šç´¢å¼•99å·²ç»å®Œæˆäº†ï¼Œä½†åˆ¤æ–­ä¸ºæœªå®Œæˆ
    
    åœºæ™¯3ï¼šå¦ä¸€ä¸ªæº¢å‡ºæƒ…å†µ
        wqe_counter = 50   (æº¢å‡ºåçš„å€¼ï¼Œå®é™…å·²æ¶ˆè´¹äº† 65535 + 50 = 65685 ä¸ªWQE)
        idx = 100          (éœ€è¦ç­‰å¾…ç´¢å¼• 99)
        ç›´æ¥æ¯”è¾ƒ: idx < wqe_counter â†’ 100 < 50 â†’ false âœ—
        ç»“è®º: é”™è¯¯ï¼å®é™…ä¸Šç´¢å¼•99æ—©å°±å®Œæˆäº†ï¼Œä½†åˆ¤æ–­ä¸ºæœªå®Œæˆ
    */
    uint16_t wqe_counter;
    do {
        // &cqe64->wqe_counter = å·²æ¶ˆè´¹çš„æœ€å¤§WQEç´¢å¼• + 1
        // ä½¿ç”¨PTXæŒ‡ä»¤è¿›è¡Œå­—èŠ‚åºè½¬æ¢ã€‚å°†ä¸»æœºå­—èŠ‚åºè½¬æ¢ä¸ºå¤§ç«¯åºï¼ˆç¡¬ä»¶ä½¿ç”¨å¤§ç«¯åºï¼‰
        wqe_counter = HtoBE16(ld_na_relaxed(&cqe64->wqe_counter));
    } while ((static_cast<uint16_t>(static_cast<uint16_t>(idx) - wqe_counter - static_cast<uint16_t>(2)) < ncqes));
    *cq->cons_idx = idx;  // è½¯ä»¶ç»´æŠ¤æ¶ˆè´¹è€…ç´¢å¼•ï¼Œå·²è½®è¯¢å®Œæˆçš„æœ€å¤§ WQE ç´¢å¼• + 1ã€‚

    // Prevent reordering of this function and later instructions
    // é˜²æ­¢å‡½æ•°è¿”å›åçš„æŒ‡ä»¤è¢«é‡æ’åºåˆ°ç´¢å¼•æ›´æ–°ä¹‹å‰ã€‚ç¡®ä¿å…¶ä»–çº¿ç¨‹èƒ½çœ‹åˆ°æ›´æ–°åçš„ cons_idx
    memory_fence_cta();
}

// Wait until wqe `idx - 1` is completed.
/*
ç­‰å¾…æŒ‡å®šç›®æ ‡ PE çš„æŒ‡å®š QP ä¸Šæ‰€æœ‰å·²æäº¤çš„ RDMA æ“ä½œå®Œæˆã€‚ç”¨äºç¡®ä¿åœ¨æ¸…ç†ç¼“å†²åŒºæˆ–è¿›è¡ŒåŒæ­¥æ“ä½œå‰ï¼Œæ‰€æœ‰æœªå®Œæˆçš„ RDMA å†™æ“ä½œå·²å®Œæˆã€‚
*/
__device__ static __forceinline__ void nvshmemi_ibgda_quiet(int dst_pe, int qp_id) {
    // qpï¼šç±»å‹ä¸º nvshmemi_ibgda_device_qp_t*ï¼ŒæŒ‡å‘ç›®æ ‡ PE çš„æŒ‡å®š QP
    auto qp = ibgda_get_rc(dst_pe, qp_id);
    // stateï¼šç±»å‹ä¸º nvshmemi_ibgda_device_state_t*ï¼ŒæŒ‡å‘ IBGDA å…¨å±€çŠ¶æ€
    auto state = ibgda_get_state();
    /*
    prod_idxï¼šå½“å‰PEéœ€è¦ç­‰å¾…å®Œæˆå½“å‰PEçš„QPçš„æœ€å¤§ WQE ç´¢å¼•ã€‚
    use_async_postsendï¼šæ˜¯å¦ä½¿ç”¨å¼‚æ­¥æäº¤æ¨¡å¼ã€‚
    å¼‚æ­¥æ¨¡å¼ã€‚ç‰¹ç‚¹: é«˜ååé‡ï¼ŒNIC æ‰¹é‡å¤„ç†ã€‚å»¶è¿Ÿè¾ƒé«˜ï¼Œé€‚åˆè®­ç»ƒé˜¶æ®µã€‚
        qp->tx_wq.prod_idx æ˜¯æŒ‡å‘å·²æäº¤ç»™ NIC çš„ WQE ç´¢å¼•çš„æŒ‡é’ˆã€‚NIC è‡ªåŠ¨è½®è¯¢å¹¶æ›´æ–°è¯¥ç´¢å¼•ã€‚è¯¥å€¼è¡¨ç¤ºâ€œå·²æäº¤ç»™ NIC çš„æœ€å¤§ WQE ç´¢å¼•â€ã€‚
        ld_na_relaxedï¼š
            ä½¿ç”¨ PTX ld.relaxed.gpu.global.L1::no_allocate æŒ‡ä»¤
            éå¯¹é½ã€relaxed å†…å­˜é¡ºåºã€ä¸ç¼“å­˜åˆ° L1
            æ€§èƒ½ä¼˜åŒ–ï¼šé¿å…ç¼“å­˜æ±¡æŸ“ï¼Œé€‚åˆä¸€æ¬¡æ€§è¯»å–
    åŒæ­¥æ¨¡å¼ã€‚ç‰¹ç‚¹: ä½å»¶è¿Ÿï¼ŒGPU ç«‹å³è§¦å‘ã€‚éœ€è¦æ˜¾å¼é—¨é“ƒï¼Œé€‚åˆæ¨ç†é˜¶æ®µã€‚
        qp->mvars.tx_wq.ready_head æ˜¯å·²å‡†å¤‡å¥½æäº¤çš„ WQE ç´¢å¼•ã€‚GPU æ˜¾å¼æ§åˆ¶æäº¤ï¼Œé€šè¿‡é—¨é“ƒé€šçŸ¥ NICã€‚è¯»å–è¯¥å€¼è¡¨ç¤ºâ€œå·²å‡†å¤‡å¥½æäº¤çš„æœ€å¤§ WQE ç´¢å¼•â€ã€‚
    
    // QPç»“æ„ä½“ä¸­çš„æŒ‡é’ˆ
    qp->tx_wq.prod_idx  // æŒ‡å‘ mvars->tx_wq.prod_idx æˆ–å†…éƒ¨ prod_idx

    // ç®¡ç†å˜é‡ä¸­çš„å€¼
    qp->mvars.tx_wq.prod_idx     // å·²æäº¤ç»™NICçš„WQEç´¢å¼•ï¼ˆå¼‚æ­¥æ¨¡å¼ä½¿ç”¨ï¼‰
    qp->mvars.tx_wq.ready_head   // å·²å‡†å¤‡å¥½æäº¤çš„WQEç´¢å¼•ï¼ˆåŒæ­¥æ¨¡å¼ä½¿ç”¨ï¼‰

    */
    uint64_t prod_idx = state->use_async_postsend ? ld_na_relaxed(qp->tx_wq.prod_idx) : ld_na_relaxed(&qp->mvars.tx_wq.ready_head);
    
    /*
    ibgda_poll_cq ä½œç”¨: è½®è¯¢ CQï¼Œç›´åˆ°æ‰€æœ‰ç´¢å¼•å°äº prod_idx çš„ WQE éƒ½å·²å®Œæˆã€‚
    qp->tx_wq.cq: å®Œæˆé˜Ÿåˆ—ï¼ˆCompletion Queueï¼‰æŒ‡é’ˆã€‚
    prod_idx: éœ€è¦ç­‰å¾…å®Œæˆçš„æœ€å¤§ WQE ç´¢å¼•ã€‚
    */
    ibgda_poll_cq(qp->tx_wq.cq, prod_idx);
}

}  // namespace deep_ep
